{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7504b51",
   "metadata": {},
   "source": [
    "# Dataset Overview\n",
    "\n",
    "- Lebih banyak pecut AI untuk ngoding, fokus dalam mencoba memahami proses statistik data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "272239c3",
   "metadata": {},
   "source": [
    "# 1. Head of Dataset and Data Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5d815ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading datasets into df1, df2, df3, df4, df5...\n",
      "All datasets loaded successfully.\n",
      "\n",
      "=============================================\n",
      "Overview for: df1 (test1_menu.csv)\n",
      "=============================================\n",
      "\n",
      "--- Head (first 5 rows) ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>device_type</th>\n",
       "      <th>browser</th>\n",
       "      <th>region</th>\n",
       "      <th>variant</th>\n",
       "      <th>pages_viewed</th>\n",
       "      <th>added_to_cart</th>\n",
       "      <th>bounced</th>\n",
       "      <th>revenue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sess_000000</td>\n",
       "      <td>user_001861</td>\n",
       "      <td>2021-03-07</td>\n",
       "      <td>desktop</td>\n",
       "      <td>Safari</td>\n",
       "      <td>Osijek</td>\n",
       "      <td>A_horizontal_menu</td>\n",
       "      <td>2.299070</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.767615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sess_000001</td>\n",
       "      <td>user_001205</td>\n",
       "      <td>2021-03-04</td>\n",
       "      <td>mobile</td>\n",
       "      <td>Chrome</td>\n",
       "      <td>Other</td>\n",
       "      <td>A_horizontal_menu</td>\n",
       "      <td>2.071886</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.354004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sess_000002</td>\n",
       "      <td>user_000685</td>\n",
       "      <td>2021-03-05</td>\n",
       "      <td>desktop</td>\n",
       "      <td>Chrome</td>\n",
       "      <td>Rijeka</td>\n",
       "      <td>A_horizontal_menu</td>\n",
       "      <td>3.159581</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.547931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sess_000003</td>\n",
       "      <td>user_001851</td>\n",
       "      <td>2021-03-07</td>\n",
       "      <td>desktop</td>\n",
       "      <td>Chrome</td>\n",
       "      <td>Split</td>\n",
       "      <td>A_horizontal_menu</td>\n",
       "      <td>2.568082</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.348691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sess_000004</td>\n",
       "      <td>user_000187</td>\n",
       "      <td>2021-03-03</td>\n",
       "      <td>mobile</td>\n",
       "      <td>Chrome</td>\n",
       "      <td>Split</td>\n",
       "      <td>A_horizontal_menu</td>\n",
       "      <td>1.433892</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.790300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    session_id      user_id   timestamp device_type browser  region  \\\n",
       "0  sess_000000  user_001861  2021-03-07     desktop  Safari  Osijek   \n",
       "1  sess_000001  user_001205  2021-03-04      mobile  Chrome   Other   \n",
       "2  sess_000002  user_000685  2021-03-05     desktop  Chrome  Rijeka   \n",
       "3  sess_000003  user_001851  2021-03-07     desktop  Chrome   Split   \n",
       "4  sess_000004  user_000187  2021-03-03      mobile  Chrome   Split   \n",
       "\n",
       "             variant  pages_viewed  added_to_cart  bounced   revenue  \n",
       "0  A_horizontal_menu      2.299070              1        1  2.767615  \n",
       "1  A_horizontal_menu      2.071886              1        0  2.354004  \n",
       "2  A_horizontal_menu      3.159581              1        0  0.547931  \n",
       "3  A_horizontal_menu      2.568082              1        0  5.348691  \n",
       "4  A_horizontal_menu      1.433892              1        0  2.790300  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Data Types and Non-Null Counts ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7000 entries, 0 to 6999\n",
      "Data columns (total 11 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   session_id     7000 non-null   object \n",
      " 1   user_id        7000 non-null   object \n",
      " 2   timestamp      7000 non-null   object \n",
      " 3   device_type    7000 non-null   object \n",
      " 4   browser        7000 non-null   object \n",
      " 5   region         7000 non-null   object \n",
      " 6   variant        7000 non-null   object \n",
      " 7   pages_viewed   7000 non-null   float64\n",
      " 8   added_to_cart  7000 non-null   int64  \n",
      " 9   bounced        7000 non-null   int64  \n",
      " 10  revenue        7000 non-null   float64\n",
      "dtypes: float64(2), int64(2), object(7)\n",
      "memory usage: 601.7+ KB\n",
      "\n",
      "============================================================\n",
      "\n",
      "=============================================\n",
      "Overview for: df2 (test2_novelty_slider.csv)\n",
      "=============================================\n",
      "\n",
      "--- Head (first 5 rows) ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>device_type</th>\n",
       "      <th>browser</th>\n",
       "      <th>region</th>\n",
       "      <th>variant</th>\n",
       "      <th>is_registered</th>\n",
       "      <th>novelty_revenue</th>\n",
       "      <th>products_added_from_novelties</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sess_000000</td>\n",
       "      <td>user_003937</td>\n",
       "      <td>2021-03-13</td>\n",
       "      <td>desktop</td>\n",
       "      <td>Chrome</td>\n",
       "      <td>Zagreb</td>\n",
       "      <td>A_manual_novelties</td>\n",
       "      <td>1</td>\n",
       "      <td>6.611739</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sess_000001</td>\n",
       "      <td>user_005445</td>\n",
       "      <td>2021-03-18</td>\n",
       "      <td>mobile</td>\n",
       "      <td>Safari</td>\n",
       "      <td>Rijeka</td>\n",
       "      <td>A_manual_novelties</td>\n",
       "      <td>1</td>\n",
       "      <td>2.508166</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sess_000002</td>\n",
       "      <td>user_001121</td>\n",
       "      <td>2021-03-13</td>\n",
       "      <td>mobile</td>\n",
       "      <td>Chrome</td>\n",
       "      <td>Zagreb</td>\n",
       "      <td>A_manual_novelties</td>\n",
       "      <td>1</td>\n",
       "      <td>3.860873</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sess_000003</td>\n",
       "      <td>user_002155</td>\n",
       "      <td>2021-03-19</td>\n",
       "      <td>mobile</td>\n",
       "      <td>Safari</td>\n",
       "      <td>Split</td>\n",
       "      <td>A_manual_novelties</td>\n",
       "      <td>1</td>\n",
       "      <td>5.869096</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sess_000004</td>\n",
       "      <td>user_000349</td>\n",
       "      <td>2021-03-15</td>\n",
       "      <td>tablet</td>\n",
       "      <td>Firefox</td>\n",
       "      <td>Zagreb</td>\n",
       "      <td>A_manual_novelties</td>\n",
       "      <td>0</td>\n",
       "      <td>1.404599</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    session_id      user_id   timestamp device_type  browser  region  \\\n",
       "0  sess_000000  user_003937  2021-03-13     desktop   Chrome  Zagreb   \n",
       "1  sess_000001  user_005445  2021-03-18      mobile   Safari  Rijeka   \n",
       "2  sess_000002  user_001121  2021-03-13      mobile   Chrome  Zagreb   \n",
       "3  sess_000003  user_002155  2021-03-19      mobile   Safari   Split   \n",
       "4  sess_000004  user_000349  2021-03-15      tablet  Firefox  Zagreb   \n",
       "\n",
       "              variant  is_registered  novelty_revenue  \\\n",
       "0  A_manual_novelties              1         6.611739   \n",
       "1  A_manual_novelties              1         2.508166   \n",
       "2  A_manual_novelties              1         3.860873   \n",
       "3  A_manual_novelties              1         5.869096   \n",
       "4  A_manual_novelties              0         1.404599   \n",
       "\n",
       "   products_added_from_novelties  \n",
       "0                              0  \n",
       "1                              0  \n",
       "2                              0  \n",
       "3                              0  \n",
       "4                              0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Data Types and Non-Null Counts ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 16000 entries, 0 to 15999\n",
      "Data columns (total 10 columns):\n",
      " #   Column                         Non-Null Count  Dtype  \n",
      "---  ------                         --------------  -----  \n",
      " 0   session_id                     16000 non-null  object \n",
      " 1   user_id                        16000 non-null  object \n",
      " 2   timestamp                      16000 non-null  object \n",
      " 3   device_type                    16000 non-null  object \n",
      " 4   browser                        16000 non-null  object \n",
      " 5   region                         16000 non-null  object \n",
      " 6   variant                        16000 non-null  object \n",
      " 7   is_registered                  16000 non-null  int64  \n",
      " 8   novelty_revenue                16000 non-null  float64\n",
      " 9   products_added_from_novelties  16000 non-null  int64  \n",
      "dtypes: float64(1), int64(2), object(7)\n",
      "memory usage: 1.2+ MB\n",
      "\n",
      "============================================================\n",
      "\n",
      "=============================================\n",
      "Overview for: df3 (test3_product_sliders.csv)\n",
      "=============================================\n",
      "\n",
      "--- Head (first 5 rows) ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>device_type</th>\n",
       "      <th>browser</th>\n",
       "      <th>region</th>\n",
       "      <th>variant</th>\n",
       "      <th>add_to_cart_rate</th>\n",
       "      <th>slider_interactions</th>\n",
       "      <th>revenue_from_recommendations</th>\n",
       "      <th>products_per_order</th>\n",
       "      <th>avg_product_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sess_000000</td>\n",
       "      <td>user_000567</td>\n",
       "      <td>2021-03-31</td>\n",
       "      <td>mobile</td>\n",
       "      <td>Firefox</td>\n",
       "      <td>Zagreb</td>\n",
       "      <td>A_selected_by_others_only</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.471560</td>\n",
       "      <td>3.096859</td>\n",
       "      <td>3.284346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sess_000001</td>\n",
       "      <td>user_002296</td>\n",
       "      <td>2021-03-28</td>\n",
       "      <td>desktop</td>\n",
       "      <td>Safari</td>\n",
       "      <td>Zagreb</td>\n",
       "      <td>A_selected_by_others_only</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2.661356</td>\n",
       "      <td>3.533376</td>\n",
       "      <td>3.617489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sess_000002</td>\n",
       "      <td>user_002093</td>\n",
       "      <td>2021-04-05</td>\n",
       "      <td>desktop</td>\n",
       "      <td>Safari</td>\n",
       "      <td>Rijeka</td>\n",
       "      <td>A_selected_by_others_only</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.171862</td>\n",
       "      <td>2.662017</td>\n",
       "      <td>4.786812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sess_000003</td>\n",
       "      <td>user_003489</td>\n",
       "      <td>2021-04-03</td>\n",
       "      <td>desktop</td>\n",
       "      <td>Safari</td>\n",
       "      <td>Osijek</td>\n",
       "      <td>A_selected_by_others_only</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4.125438</td>\n",
       "      <td>3.888011</td>\n",
       "      <td>5.257324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sess_000004</td>\n",
       "      <td>user_000446</td>\n",
       "      <td>2021-03-29</td>\n",
       "      <td>desktop</td>\n",
       "      <td>Chrome</td>\n",
       "      <td>Split</td>\n",
       "      <td>A_selected_by_others_only</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.884486</td>\n",
       "      <td>2.126060</td>\n",
       "      <td>3.966839</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    session_id      user_id   timestamp device_type  browser  region  \\\n",
       "0  sess_000000  user_000567  2021-03-31      mobile  Firefox  Zagreb   \n",
       "1  sess_000001  user_002296  2021-03-28     desktop   Safari  Zagreb   \n",
       "2  sess_000002  user_002093  2021-04-05     desktop   Safari  Rijeka   \n",
       "3  sess_000003  user_003489  2021-04-03     desktop   Safari  Osijek   \n",
       "4  sess_000004  user_000446  2021-03-29     desktop   Chrome   Split   \n",
       "\n",
       "                     variant  add_to_cart_rate  slider_interactions  \\\n",
       "0  A_selected_by_others_only                 0                    1   \n",
       "1  A_selected_by_others_only                 0                    4   \n",
       "2  A_selected_by_others_only                 0                    2   \n",
       "3  A_selected_by_others_only                 0                    2   \n",
       "4  A_selected_by_others_only                 0                    2   \n",
       "\n",
       "   revenue_from_recommendations  products_per_order  avg_product_price  \n",
       "0                      3.471560            3.096859           3.284346  \n",
       "1                      2.661356            3.533376           3.617489  \n",
       "2                      1.171862            2.662017           4.786812  \n",
       "3                      4.125438            3.888011           5.257324  \n",
       "4                      1.884486            2.126060           3.966839  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Data Types and Non-Null Counts ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 18000 entries, 0 to 17999\n",
      "Data columns (total 12 columns):\n",
      " #   Column                        Non-Null Count  Dtype  \n",
      "---  ------                        --------------  -----  \n",
      " 0   session_id                    18000 non-null  object \n",
      " 1   user_id                       18000 non-null  object \n",
      " 2   timestamp                     18000 non-null  object \n",
      " 3   device_type                   18000 non-null  object \n",
      " 4   browser                       18000 non-null  object \n",
      " 5   region                        18000 non-null  object \n",
      " 6   variant                       18000 non-null  object \n",
      " 7   add_to_cart_rate              18000 non-null  int64  \n",
      " 8   slider_interactions           18000 non-null  int64  \n",
      " 9   revenue_from_recommendations  18000 non-null  float64\n",
      " 10  products_per_order            18000 non-null  float64\n",
      " 11  avg_product_price             18000 non-null  float64\n",
      "dtypes: float64(3), int64(2), object(7)\n",
      "memory usage: 1.6+ MB\n",
      "\n",
      "============================================================\n",
      "\n",
      "=============================================\n",
      "Overview for: df4 (test4_reviews.csv)\n",
      "=============================================\n",
      "\n",
      "--- Head (first 5 rows) ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>device_type</th>\n",
       "      <th>browser</th>\n",
       "      <th>region</th>\n",
       "      <th>variant</th>\n",
       "      <th>converted</th>\n",
       "      <th>added_to_cart</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sess_000000</td>\n",
       "      <td>user_001127</td>\n",
       "      <td>2021-04-11</td>\n",
       "      <td>mobile</td>\n",
       "      <td>Chrome</td>\n",
       "      <td>Other</td>\n",
       "      <td>A_no_featured_reviews</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sess_000001</td>\n",
       "      <td>user_006812</td>\n",
       "      <td>2021-05-02</td>\n",
       "      <td>mobile</td>\n",
       "      <td>Chrome</td>\n",
       "      <td>Rijeka</td>\n",
       "      <td>A_no_featured_reviews</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sess_000002</td>\n",
       "      <td>user_004380</td>\n",
       "      <td>2021-04-27</td>\n",
       "      <td>mobile</td>\n",
       "      <td>Chrome</td>\n",
       "      <td>Zagreb</td>\n",
       "      <td>A_no_featured_reviews</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sess_000003</td>\n",
       "      <td>user_009545</td>\n",
       "      <td>2021-04-29</td>\n",
       "      <td>mobile</td>\n",
       "      <td>Chrome</td>\n",
       "      <td>Zagreb</td>\n",
       "      <td>A_no_featured_reviews</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sess_000004</td>\n",
       "      <td>user_012102</td>\n",
       "      <td>2021-05-08</td>\n",
       "      <td>mobile</td>\n",
       "      <td>Chrome</td>\n",
       "      <td>Other</td>\n",
       "      <td>A_no_featured_reviews</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    session_id      user_id   timestamp device_type browser  region  \\\n",
       "0  sess_000000  user_001127  2021-04-11      mobile  Chrome   Other   \n",
       "1  sess_000001  user_006812  2021-05-02      mobile  Chrome  Rijeka   \n",
       "2  sess_000002  user_004380  2021-04-27      mobile  Chrome  Zagreb   \n",
       "3  sess_000003  user_009545  2021-04-29      mobile  Chrome  Zagreb   \n",
       "4  sess_000004  user_012102  2021-05-08      mobile  Chrome   Other   \n",
       "\n",
       "                 variant  converted  added_to_cart  \n",
       "0  A_no_featured_reviews        0.0              1  \n",
       "1  A_no_featured_reviews        0.0              1  \n",
       "2  A_no_featured_reviews        0.0              1  \n",
       "3  A_no_featured_reviews        0.0              1  \n",
       "4  A_no_featured_reviews        0.0              1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Data Types and Non-Null Counts ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 42000 entries, 0 to 41999\n",
      "Data columns (total 9 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   session_id     42000 non-null  object \n",
      " 1   user_id        42000 non-null  object \n",
      " 2   timestamp      42000 non-null  object \n",
      " 3   device_type    42000 non-null  object \n",
      " 4   browser        42000 non-null  object \n",
      " 5   region         42000 non-null  object \n",
      " 6   variant        42000 non-null  object \n",
      " 7   converted      42000 non-null  float64\n",
      " 8   added_to_cart  42000 non-null  int64  \n",
      "dtypes: float64(1), int64(1), object(7)\n",
      "memory usage: 2.9+ MB\n",
      "\n",
      "============================================================\n",
      "\n",
      "=============================================\n",
      "Overview for: df5 (test5_search_engine.csv)\n",
      "=============================================\n",
      "\n",
      "--- Head (first 5 rows) ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>device_type</th>\n",
       "      <th>browser</th>\n",
       "      <th>region</th>\n",
       "      <th>variant</th>\n",
       "      <th>avg_revenue_per_visitor</th>\n",
       "      <th>added_to_cart</th>\n",
       "      <th>converted</th>\n",
       "      <th>interacted_with_search</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sess_000000</td>\n",
       "      <td>user_001321</td>\n",
       "      <td>2021-06-13</td>\n",
       "      <td>desktop</td>\n",
       "      <td>Chrome</td>\n",
       "      <td>Other</td>\n",
       "      <td>A_hybris_search</td>\n",
       "      <td>1.066146</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sess_000001</td>\n",
       "      <td>user_000722</td>\n",
       "      <td>2021-06-17</td>\n",
       "      <td>mobile</td>\n",
       "      <td>Safari</td>\n",
       "      <td>Split</td>\n",
       "      <td>A_hybris_search</td>\n",
       "      <td>0.817668</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sess_000002</td>\n",
       "      <td>user_000665</td>\n",
       "      <td>2021-06-14</td>\n",
       "      <td>mobile</td>\n",
       "      <td>Chrome</td>\n",
       "      <td>Zagreb</td>\n",
       "      <td>A_hybris_search</td>\n",
       "      <td>1.341627</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sess_000003</td>\n",
       "      <td>user_002173</td>\n",
       "      <td>2021-06-14</td>\n",
       "      <td>desktop</td>\n",
       "      <td>Chrome</td>\n",
       "      <td>Other</td>\n",
       "      <td>A_hybris_search</td>\n",
       "      <td>1.389355</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sess_000004</td>\n",
       "      <td>user_001023</td>\n",
       "      <td>2021-06-13</td>\n",
       "      <td>desktop</td>\n",
       "      <td>Chrome</td>\n",
       "      <td>Other</td>\n",
       "      <td>A_hybris_search</td>\n",
       "      <td>0.285824</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    session_id      user_id   timestamp device_type browser  region  \\\n",
       "0  sess_000000  user_001321  2021-06-13     desktop  Chrome   Other   \n",
       "1  sess_000001  user_000722  2021-06-17      mobile  Safari   Split   \n",
       "2  sess_000002  user_000665  2021-06-14      mobile  Chrome  Zagreb   \n",
       "3  sess_000003  user_002173  2021-06-14     desktop  Chrome   Other   \n",
       "4  sess_000004  user_001023  2021-06-13     desktop  Chrome   Other   \n",
       "\n",
       "           variant  avg_revenue_per_visitor  added_to_cart  converted  \\\n",
       "0  A_hybris_search                 1.066146              1          0   \n",
       "1  A_hybris_search                 0.817668              1          0   \n",
       "2  A_hybris_search                 1.341627              1          0   \n",
       "3  A_hybris_search                 1.389355              1          0   \n",
       "4  A_hybris_search                 0.285824              1          0   \n",
       "\n",
       "   interacted_with_search  \n",
       "0                       0  \n",
       "1                       0  \n",
       "2                       1  \n",
       "3                       1  \n",
       "4                       0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Data Types and Non-Null Counts ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 19000 entries, 0 to 18999\n",
      "Data columns (total 11 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   session_id               19000 non-null  object \n",
      " 1   user_id                  19000 non-null  object \n",
      " 2   timestamp                19000 non-null  object \n",
      " 3   device_type              19000 non-null  object \n",
      " 4   browser                  19000 non-null  object \n",
      " 5   region                   19000 non-null  object \n",
      " 6   variant                  19000 non-null  object \n",
      " 7   avg_revenue_per_visitor  19000 non-null  float64\n",
      " 8   added_to_cart            19000 non-null  int64  \n",
      " 9   converted                19000 non-null  int64  \n",
      " 10  interacted_with_search   19000 non-null  int64  \n",
      "dtypes: float64(1), int64(3), object(7)\n",
      "memory usage: 1.6+ MB\n",
      "\n",
      "============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# --- Setup and Load All Datasets into Separate Variables ---\n",
    "\n",
    "base_dir = os.path.join(os.getcwd(), 'raw_dataset')\n",
    "\n",
    "file_names = [\n",
    "    'test1_menu.csv',\n",
    "    'test2_novelty_slider.csv',\n",
    "    'test3_product_sliders.csv',\n",
    "    'test4_reviews.csv',\n",
    "    'test5_search_engine.csv'\n",
    "]\n",
    "\n",
    "paths = [os.path.join(base_dir, name) for name in file_names]\n",
    "\n",
    "print(\"Loading datasets into df1, df2, df3, df4, df5...\")\n",
    "df1 = pd.read_csv(paths[0])\n",
    "df2 = pd.read_csv(paths[1])\n",
    "df3 = pd.read_csv(paths[2])\n",
    "df4 = pd.read_csv(paths[3])\n",
    "df5 = pd.read_csv(paths[4])\n",
    "print(\"All datasets loaded successfully.\\n\")\n",
    "\n",
    "# --- Initial Inspection of Each DataFrame ---\n",
    "\n",
    "# Create a dictionary for easy iteration\n",
    "dataframes = {\n",
    "    \"df1 (test1_menu.csv)\": df1,\n",
    "    \"df2 (test2_novelty_slider.csv)\": df2,\n",
    "    \"df3 (test3_product_sliders.csv)\": df3,\n",
    "    \"df4 (test4_reviews.csv)\": df4,\n",
    "    \"df5 (test5_search_engine.csv)\": df5\n",
    "}\n",
    "\n",
    "for name, df in dataframes.items():\n",
    "    print(f\"=============================================\")\n",
    "    print(f\"Overview for: {name}\")\n",
    "    print(f\"=============================================\")\n",
    "    \n",
    "    print(\"\\n--- Head (first 5 rows) ---\")\n",
    "    display(df.head())\n",
    "    \n",
    "    print(\"\\n--- Data Types and Non-Null Counts ---\")\n",
    "    df.info()\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60 + \"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a435de7",
   "metadata": {},
   "source": [
    "# 2. Validation Check"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc823873",
   "metadata": {},
   "source": [
    "Validation for each dataset using \n",
    "* Sample Ratio Mismatch (SRM) detection\n",
    "* Covariate balance verification\n",
    "* Temporal stability checks\n",
    "* Multiple testing correction (Benjamini-Hochberg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab3a7639",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "COMPREHENSIVE VALIDATION SUITE\n",
      "Validating All 5 A/B Tests\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "TEST: Test 1: Menu Design\n",
      "================================================================================\n",
      "Loaded: 7,000 rows\n",
      "Variants (2):\n",
      "   - A_horizontal_menu: 3,500 (50.0%)\n",
      "   - B_dropdown_menu: 3,500 (50.0%)\n",
      "\n",
      "Validation Results:\n",
      "  SRM Test:        PASS (p=1.0000)\n",
      "  Balance:         OK (SMD=0.026)\n",
      "  Temporal:        OK (CV=0.057)\n",
      "\n",
      "================================================================================\n",
      "TEST: Test 2: Novelty Slider\n",
      "================================================================================\n",
      "Loaded: 16,000 rows\n",
      "Variants (2):\n",
      "   - A_manual_novelties: 8,000 (50.0%)\n",
      "   - B_personalized_novelties: 8,000 (50.0%)\n",
      "\n",
      "Validation Results:\n",
      "  SRM Test:        PASS (p=1.0000)\n",
      "  Balance:         OK (SMD=0.028)\n",
      "  Temporal:        OK (CV=0.038)\n",
      "\n",
      "================================================================================\n",
      "TEST: Test 3: Product Sliders\n",
      "================================================================================\n",
      "Loaded: 18,000 rows\n",
      "Variants (3):\n",
      "   - A_selected_by_others_only: 6,000 (33.3%)\n",
      "   - B_similar_products_top: 6,000 (33.3%)\n",
      "   - C_selected_by_others_top: 6,000 (33.3%)\n",
      "\n",
      "Validation Results:\n",
      "  SRM Test:        PASS (p=1.0000)\n",
      "  Balance:         OK (SMD=0.039)\n",
      "  Temporal:        OK (CV=0.049)\n",
      "\n",
      "================================================================================\n",
      "TEST: Test 4: Customer Reviews\n",
      "================================================================================\n",
      "Loaded: 42,000 rows\n",
      "Variants (2):\n",
      "   - A_no_featured_reviews: 21,000 (50.0%)\n",
      "   - B_featured_reviews: 21,000 (50.0%)\n",
      "\n",
      "Validation Results:\n",
      "  SRM Test:        PASS (p=1.0000)\n",
      "  Balance:         OK (SMD=0.014)\n",
      "  Temporal:        OK (CV=0.047)\n",
      "\n",
      "================================================================================\n",
      "TEST: Test 5: Search Engine\n",
      "================================================================================\n",
      "Loaded: 19,000 rows\n",
      "Variants (2):\n",
      "   - A_hybris_search: 9,500 (50.0%)\n",
      "   - B_algolia_search: 9,500 (50.0%)\n",
      "\n",
      "Validation Results:\n",
      "  SRM Test:        PASS (p=1.0000)\n",
      "  Balance:         OK (SMD=0.032)\n",
      "  Temporal:        OK (CV=0.026)\n",
      "\n",
      "\n",
      "================================================================================\n",
      "SUMMARY TABLE\n",
      "================================================================================\n",
      "\n",
      "Test                                  N      SRM    Balance   Temporal    Valid\n",
      "--------------------------------------------------------------------------------\n",
      "Test 1: Menu Design               7,000     PASS       Good     Stable      YES\n",
      "Test 2: Novelty Slider           16,000     PASS       Good     Stable      YES\n",
      "Test 3: Product Sliders          18,000     PASS       Good     Stable      YES\n",
      "Test 4: Customer Reviews         42,000     PASS       Good     Stable      YES\n",
      "Test 5: Search Engine            19,000     PASS       Good     Stable      YES\n",
      "\n",
      "================================================================================\n",
      "OVERALL STATISTICS\n",
      "================================================================================\n",
      "\n",
      "Total samples across all tests: 102,000\n",
      "Tests passed SRM check: 5/5\n",
      "Tests fully valid: 5/5\n",
      "\n",
      " ALL TESTS ARE VALID\n",
      "\n",
      "All experiments passed validation checks!\n",
      "You can proceed with statistical analysis with full confidence.\n",
      "\n",
      "================================================================================\n",
      "RECOMMENDATIONS BY TEST\n",
      "================================================================================\n",
      "\n",
      "Test 1: Menu Design:\n",
      "All checks passed - proceed with analysis\n",
      "\n",
      "Test 2: Novelty Slider:\n",
      "All checks passed - proceed with analysis\n",
      "\n",
      "Test 3: Product Sliders:\n",
      "All checks passed - proceed with analysis\n",
      "\n",
      "Test 4: Customer Reviews:\n",
      "All checks passed - proceed with analysis\n",
      "\n",
      "Test 5: Search Engine:\n",
      "All checks passed - proceed with analysis\n",
      "\n",
      "================================================================================\n",
      "VALIDATION COMPLETE\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Complete Experimental Validation Framework for A/B Testing\n",
    "\n",
    "Implements ALL required validation checks:\n",
    "1. Sample Ratio Mismatch (SRM) Detection \n",
    "2. Covariate Balance Verification \n",
    "3. Temporal Stability Checks \n",
    "4. Multiple Testing Correction\n",
    "\n",
    "When run directly, validates all 5 A/B tests with comprehensive reporting.\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "from typing import Dict, List, Tuple, Optional, Union\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "\n",
    "class ExperimentValidator:\n",
    "    \"\"\"\n",
    "    Complete validation framework for A/B tests.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 srm_threshold: float = 0.001,\n",
    "                 balance_threshold: float = 0.2,\n",
    "                 temporal_threshold: float = 0.2):\n",
    "        self.srm_threshold = srm_threshold\n",
    "        self.balance_threshold = balance_threshold\n",
    "        self.temporal_threshold = temporal_threshold\n",
    "    \n",
    "    def sample_ratio_mismatch_test(self,\n",
    "                                   df: pd.DataFrame,\n",
    "                                   variant_col: str,\n",
    "                                   expected_ratio: Optional[Dict[str, float]] = None) -> Dict:\n",
    "        \"\"\"Sample Ratio Mismatch detection.\"\"\"\n",
    "        \n",
    "        observed = df[variant_col].value_counts().sort_index()\n",
    "        total = len(df)\n",
    "        n_variants = len(observed)\n",
    "        \n",
    "        if expected_ratio is None:\n",
    "            expected = pd.Series([total / n_variants] * n_variants, index=observed.index)\n",
    "        else:\n",
    "            expected = pd.Series({k: v * total for k, v in expected_ratio.items()})\n",
    "        \n",
    "        chi2_stat = np.sum((observed - expected)**2 / expected)\n",
    "        df_chi = n_variants - 1\n",
    "        pvalue = 1 - stats.chi2.cdf(chi2_stat, df_chi)\n",
    "        \n",
    "        has_srm = pvalue < self.srm_threshold\n",
    "        \n",
    "        result = {\n",
    "            'test': 'sample_ratio_mismatch',\n",
    "            'chi2_statistic': chi2_stat,\n",
    "            'degrees_of_freedom': df_chi,\n",
    "            'pvalue': pvalue,\n",
    "            'threshold': self.srm_threshold,\n",
    "            'has_srm': has_srm,\n",
    "            'observed_counts': observed.to_dict(),\n",
    "            'expected_counts': expected.to_dict(),\n",
    "            'observed_ratio': (observed / total).to_dict(),\n",
    "            'expected_ratio': (expected / total).to_dict()\n",
    "        }\n",
    "        \n",
    "        if has_srm:\n",
    "            result['warning'] = f\"CRITICAL: SRM detected (p={pvalue:.6f} < {self.srm_threshold}). Experiment is INVALID.\"\n",
    "        else:\n",
    "            result['message'] = f\"No SRM detected (p={pvalue:.4f}). Allocation is as expected.\"\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def covariate_balance_check(self,\n",
    "                                df: pd.DataFrame,\n",
    "                                variant_col: str,\n",
    "                                covariates: List[str],\n",
    "                                threshold: Optional[float] = None) -> Dict:\n",
    "        \"\"\"Covariate balance verification using SMD.\"\"\"\n",
    "        \n",
    "        if threshold is None:\n",
    "            threshold = self.balance_threshold\n",
    "        \n",
    "        variants = df[variant_col].unique()\n",
    "        \n",
    "        if len(variants) < 2:\n",
    "            return {'error': 'Need at least 2 variants for balance check'}\n",
    "        \n",
    "        balance_results = []\n",
    "        imbalanced_covariates = []\n",
    "        \n",
    "        for covariate in covariates:\n",
    "            if covariate not in df.columns:\n",
    "                warnings.warn(f\"Covariate '{covariate}' not found in dataframe\")\n",
    "                continue\n",
    "            \n",
    "            is_categorical = (\n",
    "                df[covariate].dtype == 'object' or \n",
    "                df[covariate].dtype.name == 'category' or\n",
    "                df[covariate].nunique() < 10\n",
    "            )\n",
    "            \n",
    "            if is_categorical:\n",
    "                for category in df[covariate].unique():\n",
    "                    proportions = {}\n",
    "                    for variant in variants:\n",
    "                        variant_data = df[df[variant_col] == variant][covariate]\n",
    "                        proportions[variant] = (variant_data == category).mean()\n",
    "                    \n",
    "                    variant_list = list(variants)\n",
    "                    p1 = proportions[variant_list[0]]\n",
    "                    p2 = proportions[variant_list[1]]\n",
    "                    p_pooled = (p1 + p2) / 2\n",
    "                    \n",
    "                    if p_pooled > 0 and p_pooled < 1:\n",
    "                        smd = abs(p1 - p2) / np.sqrt(p_pooled * (1 - p_pooled))\n",
    "                    else:\n",
    "                        smd = 0.0\n",
    "                    \n",
    "                    is_imbalanced = smd > threshold\n",
    "                    \n",
    "                    balance_results.append({\n",
    "                        'covariate': f\"{covariate}={category}\",\n",
    "                        'type': 'categorical',\n",
    "                        'variant_1': variant_list[0],\n",
    "                        'variant_2': variant_list[1],\n",
    "                        'proportion_1': p1,\n",
    "                        'proportion_2': p2,\n",
    "                        'smd': smd,\n",
    "                        'imbalanced': is_imbalanced\n",
    "                    })\n",
    "                    \n",
    "                    if is_imbalanced:\n",
    "                        imbalanced_covariates.append(f\"{covariate}={category}\")\n",
    "            else:\n",
    "                variant_stats = {}\n",
    "                for variant in variants:\n",
    "                    variant_data = df[df[variant_col] == variant][covariate]\n",
    "                    variant_stats[variant] = {\n",
    "                        'mean': variant_data.mean(),\n",
    "                        'std': variant_data.std(),\n",
    "                        'var': variant_data.var(),\n",
    "                        'n': len(variant_data)\n",
    "                    }\n",
    "                \n",
    "                variant_list = list(variants)\n",
    "                v1, v2 = variant_list[0], variant_list[1]\n",
    "                \n",
    "                mean_diff = abs(variant_stats[v1]['mean'] - variant_stats[v2]['mean'])\n",
    "                pooled_std = np.sqrt((variant_stats[v1]['var'] + variant_stats[v2]['var']) / 2)\n",
    "                \n",
    "                if pooled_std > 0:\n",
    "                    smd = mean_diff / pooled_std\n",
    "                else:\n",
    "                    smd = 0.0\n",
    "                \n",
    "                is_imbalanced = smd > threshold\n",
    "                \n",
    "                balance_results.append({\n",
    "                    'covariate': covariate,\n",
    "                    'type': 'continuous',\n",
    "                    'variant_1': variant_list[0],\n",
    "                    'variant_2': variant_list[1],\n",
    "                    'mean_1': variant_stats[v1]['mean'],\n",
    "                    'mean_2': variant_stats[v2]['mean'],\n",
    "                    'std_1': variant_stats[v1]['std'],\n",
    "                    'std_2': variant_stats[v2]['std'],\n",
    "                    'smd': smd,\n",
    "                    'imbalanced': is_imbalanced\n",
    "                })\n",
    "                \n",
    "                if is_imbalanced:\n",
    "                    imbalanced_covariates.append(covariate)\n",
    "        \n",
    "        balance_df = pd.DataFrame(balance_results)\n",
    "        max_smd = balance_df['smd'].max() if len(balance_df) > 0 else 0\n",
    "        n_imbalanced = len(imbalanced_covariates)\n",
    "        \n",
    "        if max_smd < 0.1:\n",
    "            message = f\"Excellent balance (max SMD={max_smd:.3f} < 0.1)\"\n",
    "        elif max_smd < threshold:\n",
    "            message = f\"Good balance (max SMD={max_smd:.3f} < {threshold})\"\n",
    "        else:\n",
    "            message = f\"{n_imbalanced} covariate(s) imbalanced (max SMD={max_smd:.3f} â‰¥ {threshold})\"\n",
    "        \n",
    "        return {\n",
    "            'test': 'covariate_balance',\n",
    "            'variants_compared': list(variants)[:2],\n",
    "            'balance_results': balance_df,\n",
    "            'imbalanced_covariates': imbalanced_covariates,\n",
    "            'n_imbalanced': n_imbalanced,\n",
    "            'max_smd': max_smd,\n",
    "            'threshold': threshold,\n",
    "            'message': message\n",
    "        }\n",
    "    \n",
    "    def temporal_stability_check(self,\n",
    "                                df: pd.DataFrame,\n",
    "                                variant_col: str,\n",
    "                                date_col: str,\n",
    "                                threshold: Optional[float] = None) -> Dict:\n",
    "        \"\"\"Temporal stability verification.\"\"\"\n",
    "        \n",
    "        if threshold is None:\n",
    "            threshold = self.temporal_threshold\n",
    "        \n",
    "        df = df.copy()\n",
    "        if not pd.api.types.is_datetime64_any_dtype(df[date_col]):\n",
    "            df[date_col] = pd.to_datetime(df[date_col])\n",
    "        \n",
    "        df['date'] = df[date_col].dt.date\n",
    "        daily_counts = df.groupby(['date', variant_col]).size().unstack(fill_value=0)\n",
    "        \n",
    "        cv_results = {}\n",
    "        for variant in daily_counts.columns:\n",
    "            counts = daily_counts[variant]\n",
    "            mean_count = counts.mean()\n",
    "            std_count = counts.std()\n",
    "            cv = std_count / mean_count if mean_count > 0 else 0.0\n",
    "            cv_results[variant] = cv\n",
    "        \n",
    "        max_cv = max(cv_results.values())\n",
    "        is_stable = max_cv < threshold\n",
    "        \n",
    "        message = (\n",
    "            f\"Stable allocation over time (max CV={max_cv:.3f} < {threshold})\" if is_stable\n",
    "            else f\"Unstable allocation (max CV={max_cv:.3f} â‰¥ {threshold})\"\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'test': 'temporal_stability',\n",
    "            'cv_by_variant': cv_results,\n",
    "            'max_cv': max_cv,\n",
    "            'threshold': threshold,\n",
    "            'is_stable': is_stable,\n",
    "            'daily_counts': daily_counts,\n",
    "            'n_days': len(daily_counts),\n",
    "            'message': message\n",
    "        }\n",
    "    \n",
    "    def multiple_testing_correction(self,\n",
    "                                    pvalues: List[float],\n",
    "                                    method: str = 'holm',\n",
    "                                    alpha: float = 0.05) -> Dict:\n",
    "        \"\"\"\n",
    "        Multiple testing correction.\n",
    "        \n",
    "        Methods:\n",
    "        - 'bonferroni': Most conservative (alpha/k)\n",
    "        - 'holm': Holm-Bonferroni (recommended for 5-10 tests)\n",
    "        - 'fdr_bh': Benjamini-Hochberg FDR (for >10 tests)\n",
    "        \n",
    "        References:\n",
    "        - Bonferroni (1936)\n",
    "        - Holm (1979)\n",
    "        - Benjamini & Hochberg (1995)\n",
    "        \"\"\"\n",
    "        \n",
    "        pvalues_array = np.array(pvalues)\n",
    "        n_tests = len(pvalues_array)\n",
    "        \n",
    "        # Apply correction\n",
    "        reject, pvals_corrected, alphacSidak, alphacBonf = multipletests(\n",
    "            pvalues_array,\n",
    "            alpha=alpha,\n",
    "            method=method\n",
    "        )\n",
    "        \n",
    "        method_names = {\n",
    "            'bonferroni': 'Bonferroni',\n",
    "            'holm': 'Holm-Bonferroni',\n",
    "            'fdr_bh': 'Benjamini-Hochberg FDR'\n",
    "        }\n",
    "        \n",
    "        return {\n",
    "            'test': 'multiple_testing_correction',\n",
    "            'method': method_names.get(method, method),\n",
    "            'n_tests': n_tests,\n",
    "            'alpha': alpha,\n",
    "            'original_pvalues': pvalues_array.tolist(),\n",
    "            'corrected_pvalues': pvals_corrected.tolist(),\n",
    "            'reject': reject.tolist(),\n",
    "            'n_significant_original': sum(pvalues_array < alpha),\n",
    "            'n_significant_corrected': sum(reject),\n",
    "            'message': (\n",
    "                f\"âœ“ Multiple testing correction applied: {method_names.get(method, method)}\\n\"\n",
    "                f\"  Original significant: {sum(pvalues_array < alpha)}/{n_tests}\\n\"\n",
    "                f\"  Corrected significant: {sum(reject)}/{n_tests}\"\n",
    "            )\n",
    "        }\n",
    "    \n",
    "    def run_all_validations(self,\n",
    "                           df: pd.DataFrame,\n",
    "                           variant_col: str,\n",
    "                           covariates: Optional[List[str]] = None,\n",
    "                           date_col: Optional[str] = None,\n",
    "                           metric_pvalues: Optional[List[float]] = None,\n",
    "                           correction_method: str = 'holm') -> Dict:\n",
    "        \"\"\"\n",
    "        Run complete validation suite including multiple testing correction.\n",
    "        \"\"\"\n",
    "        \n",
    "        results = {}\n",
    "        \n",
    "        print(\"=\" * 80)\n",
    "        print(\"EXPERIMENTAL VALIDATION SUITE\")\n",
    "        print(\"=\" * 80)\n",
    "        \n",
    "        # 1. SRM Test\n",
    "        print(\"\\n1. Sample Ratio Mismatch Test\")\n",
    "        print(\"-\" * 80)\n",
    "        srm_result = self.sample_ratio_mismatch_test(df, variant_col)\n",
    "        results['srm'] = srm_result\n",
    "        print(srm_result.get('message', srm_result.get('warning', '')))\n",
    "        \n",
    "        if srm_result['has_srm']:\n",
    "            print(\"\\n\" + \"=\" * 80)\n",
    "            print(\"VALIDATION FAILED: SRM detected.\")\n",
    "            print(\"=\" * 80)\n",
    "            return results\n",
    "        \n",
    "        # 2. Covariate Balance\n",
    "        if covariates:\n",
    "            print(\"\\n2. Covariate Balance Check\")\n",
    "            print(\"-\" * 80)\n",
    "            balance_result = self.covariate_balance_check(df, variant_col, covariates)\n",
    "            results['balance'] = balance_result\n",
    "            print(balance_result.get('message', ''))\n",
    "        \n",
    "        # 3. Temporal Stability\n",
    "        if date_col:\n",
    "            print(\"\\n3. Temporal Stability Check\")\n",
    "            print(\"-\" * 80)\n",
    "            temporal_result = self.temporal_stability_check(df, variant_col, date_col)\n",
    "            results['temporal'] = temporal_result\n",
    "            print(temporal_result.get('message', ''))\n",
    "        \n",
    "        # 4. Multiple Testing Correction\n",
    "        if metric_pvalues:\n",
    "            print(\"\\n4. Multiple Testing Correction\")\n",
    "            print(\"-\" * 80)\n",
    "            correction_result = self.multiple_testing_correction(\n",
    "                metric_pvalues,\n",
    "                method=correction_method,\n",
    "                alpha=0.05\n",
    "            )\n",
    "            results['multiple_testing'] = correction_result\n",
    "            print(correction_result.get('message', ''))\n",
    "        \n",
    "        # Summary\n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "        all_clear = (\n",
    "            not srm_result['has_srm'] and\n",
    "            (not covariates or balance_result.get('max_smd', 0) < self.balance_threshold) and\n",
    "            (not date_col or temporal_result.get('is_stable', True))\n",
    "        )\n",
    "        \n",
    "        if all_clear:\n",
    "            print(\"ALL VALIDATION CHECKS PASSED\")\n",
    "        else:\n",
    "            print(\"VALIDATION WARNINGS DETECTED\")\n",
    "        print(\"=\" * 80)\n",
    "        \n",
    "        return results\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# COMPREHENSIVE VALIDATION FOR ALL 5 A/B TESTS\n",
    "# ============================================================================\n",
    "\n",
    "def validate_test(test_name, csv_file, validator):\n",
    "    \"\"\"Validate a single test\"\"\"\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"TEST: {test_name}\")\n",
    "    print('='*80)\n",
    "    \n",
    "    try:\n",
    "        if os.path.exists(f'../raw_dataset/{csv_file}'):\n",
    "            df = pd.read_csv(f'../raw_dataset/{csv_file}')\n",
    "        elif os.path.exists(f'raw_dataset/{csv_file}'):\n",
    "            df = pd.read_csv(f'raw_dataset/{csv_file}')\n",
    "        else:\n",
    "            raise FileNotFoundError(f\"Cannot find {csv_file}\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File not found: {csv_file}\")\n",
    "        print(\"   Please run data_generation.py first!\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"Loaded: {len(df):,} rows\")\n",
    "    \n",
    "    # Variant split\n",
    "    variant_counts = df['variant'].value_counts()\n",
    "    print(f\"Variants ({len(variant_counts)}):\")\n",
    "    for variant, count in variant_counts.items():\n",
    "        pct = count / len(df) * 100\n",
    "        print(f\"   - {variant}: {count:,} ({pct:.1f}%)\")\n",
    "    \n",
    "    # Quick validation\n",
    "    srm = validator.sample_ratio_mismatch_test(df, 'variant')\n",
    "    balance = validator.covariate_balance_check(\n",
    "        df, 'variant', ['device_type', 'browser', 'region']\n",
    "    )\n",
    "    temporal = validator.temporal_stability_check(df, 'variant', 'timestamp')\n",
    "    \n",
    "    # Status\n",
    "    srm_status = \"PASS\" if not srm['has_srm'] else \"FAIL\"\n",
    "    balance_status = \"OK\" if balance['max_smd'] < 0.1 else \"WARNING\" if balance['max_smd'] < 0.2 else \"FAIL\"\n",
    "    temporal_status = \"OK\" if temporal['is_stable'] else \"WARNING\"\n",
    "    \n",
    "    print(f\"\\nValidation Results:\")\n",
    "    print(f\"  SRM Test:        {srm_status} (p={srm['pvalue']:.4f})\")\n",
    "    print(f\"  Balance:         {balance_status} (SMD={balance['max_smd']:.3f})\")\n",
    "    print(f\"  Temporal:        {temporal_status} (CV={temporal['max_cv']:.3f})\")\n",
    "    \n",
    "    return {\n",
    "        'test': test_name,\n",
    "        'n': len(df),\n",
    "        'n_variants': len(variant_counts),\n",
    "        'srm_pvalue': srm['pvalue'],\n",
    "        'srm_passed': not srm['has_srm'],\n",
    "        'balance_smd': balance['max_smd'],\n",
    "        'balance_ok': balance['max_smd'] < 0.2,\n",
    "        'temporal_cv': temporal['max_cv'],\n",
    "        'temporal_stable': temporal['is_stable'],\n",
    "        'overall_valid': not srm['has_srm'] and balance['max_smd'] < 0.2\n",
    "    }\n",
    "\n",
    "\n",
    "def validate_all_tests():\n",
    "    \"\"\"Run comprehensive validation on all 5 A/B tests\"\"\"\n",
    "    \n",
    "    print(\"=\"*80)\n",
    "    print(\"COMPREHENSIVE VALIDATION SUITE\")\n",
    "    print(\"Validating All 5 A/B Tests\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    validator = ExperimentValidator(\n",
    "        srm_threshold=0.001,\n",
    "        balance_threshold=0.2,\n",
    "        temporal_threshold=0.2\n",
    "    )\n",
    "    \n",
    "    tests = [\n",
    "        ('Test 1: Menu Design', 'test1_menu.csv'),\n",
    "        ('Test 2: Novelty Slider', 'test2_novelty_slider.csv'),\n",
    "        ('Test 3: Product Sliders', 'test3_product_sliders.csv'),\n",
    "        ('Test 4: Customer Reviews', 'test4_reviews.csv'),\n",
    "        ('Test 5: Search Engine', 'test5_search_engine.csv')\n",
    "    ]\n",
    "    \n",
    "    results = []\n",
    "    for test_name, csv_file in tests:\n",
    "        result = validate_test(test_name, csv_file, validator)\n",
    "        if result:\n",
    "            results.append(result)\n",
    "    \n",
    "    # Summary table\n",
    "    print(f\"\\n\\n{'='*80}\")\n",
    "    print(\"SUMMARY TABLE\")\n",
    "    print('='*80)\n",
    "    \n",
    "    if results:\n",
    "        summary_df = pd.DataFrame(results)\n",
    "        \n",
    "        print(f\"\\n{'Test':<30} {'N':>8} {'SRM':>8} {'Balance':>10} {'Temporal':>10} {'Valid':>8}\")\n",
    "        print('-'*80)\n",
    "        \n",
    "        for _, row in summary_df.iterrows():\n",
    "            test = row['test'][:28]\n",
    "            n = f\"{int(row['n']):,}\"\n",
    "            srm = \"PASS\" if row['srm_passed'] else \"FAIL\"\n",
    "            balance = \"Good\" if row['balance_ok'] else \"Warning\"\n",
    "            temporal = \"Stable\" if row['temporal_stable'] else \"Unstable\"\n",
    "            valid = \"YES\" if row['overall_valid'] else \"CHECK\"\n",
    "            \n",
    "            print(f\"{test:<30} {n:>8} {srm:>8} {balance:>10} {temporal:>10} {valid:>8}\")\n",
    "        \n",
    "        # Overall stats\n",
    "        print('\\n' + '='*80)\n",
    "        print(\"OVERALL STATISTICS\")\n",
    "        print('='*80)\n",
    "        \n",
    "        n_total = summary_df['n'].sum()\n",
    "        n_passed_srm = summary_df['srm_passed'].sum()\n",
    "        n_valid = summary_df['overall_valid'].sum()\n",
    "        \n",
    "        print(f\"\\nTotal samples across all tests: {n_total:,}\")\n",
    "        print(f\"Tests passed SRM check: {n_passed_srm}/{len(results)}\")\n",
    "        print(f\"Tests fully valid: {n_valid}/{len(results)}\")\n",
    "        \n",
    "        if n_passed_srm == len(results) and n_valid == len(results):\n",
    "            print(\"\\n ALL TESTS ARE VALID\")\n",
    "            print(\"\\nAll experiments passed validation checks!\")\n",
    "            print(\"You can proceed with statistical analysis with full confidence.\")\n",
    "        elif n_passed_srm < len(results):\n",
    "            print(\"\\n CRITICAL ISSUES DETECTED\")\n",
    "            print(\"\\nSome tests failed SRM check - DO NOT analyze those tests!\")\n",
    "        else:\n",
    "            print(\"\\nMINOR WARNINGS DETECTED\")\n",
    "            print(\"\\nTests passed critical checks but have minor balance/temporal issues.\")\n",
    "            print(\"Proceed with caution and consider causal adjustment methods.\")\n",
    "        \n",
    "        # Detailed recommendations\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"RECOMMENDATIONS BY TEST\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        for _, row in summary_df.iterrows():\n",
    "            print(f\"\\n{row['test']}:\")\n",
    "            if row['overall_valid']:\n",
    "                print(\"All checks passed - proceed with analysis\")\n",
    "            else:\n",
    "                if not row['srm_passed']:\n",
    "                    print(\"    SRM FAILED - DO NOT ANALYZE\")\n",
    "                    print(\"     â†’ Investigate randomization bug\")\n",
    "                    print(\"     â†’ Restart experiment after fix\")\n",
    "                elif not row['balance_ok']:\n",
    "                    print(\"    Balance issue detected\")\n",
    "                    print(\"     â†’ Use regression adjustment or CUPED\")\n",
    "                    print(\"     â†’ Check for selection bias\")\n",
    "                if not row['temporal_stable']:\n",
    "                    print(\"    Temporal instability detected\")\n",
    "                    print(\"     â†’ Check for system changes during test\")\n",
    "                    print(\"     â†’ Consider excluding unstable periods\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"VALIDATION COMPLETE\")\n",
    "    print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "\n",
    "\n",
    "# MAIN EXECUTION\n",
    "if __name__ == \"__main__\":\n",
    "    validate_all_tests()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b377cf68",
   "metadata": {},
   "source": [
    "# 3. Statistical Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e590005",
   "metadata": {},
   "source": [
    "### Define Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "afd3e8a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "FILE: test1_menu.csv\n",
      "==================================================\n",
      "    session_id      user_id   timestamp device_type browser  region  \\\n",
      "0  sess_000000  user_001861  2021-03-07     desktop  Safari  Osijek   \n",
      "1  sess_000001  user_001205  2021-03-04      mobile  Chrome   Other   \n",
      "2  sess_000002  user_000685  2021-03-05     desktop  Chrome  Rijeka   \n",
      "3  sess_000003  user_001851  2021-03-07     desktop  Chrome   Split   \n",
      "4  sess_000004  user_000187  2021-03-03      mobile  Chrome   Split   \n",
      "\n",
      "             variant  pages_viewed  added_to_cart  bounced   revenue  \n",
      "0  A_horizontal_menu      2.299070              1        1  2.767615  \n",
      "1  A_horizontal_menu      2.071886              1        0  2.354004  \n",
      "2  A_horizontal_menu      3.159581              1        0  0.547931  \n",
      "3  A_horizontal_menu      2.568082              1        0  5.348691  \n",
      "4  A_horizontal_menu      1.433892              1        0  2.790300  \n",
      "\n",
      "==================================================\n",
      "FILE: test2_novelty_slider.csv\n",
      "==================================================\n",
      "    session_id      user_id   timestamp device_type  browser  region  \\\n",
      "0  sess_000000  user_003937  2021-03-13     desktop   Chrome  Zagreb   \n",
      "1  sess_000001  user_005445  2021-03-18      mobile   Safari  Rijeka   \n",
      "2  sess_000002  user_001121  2021-03-13      mobile   Chrome  Zagreb   \n",
      "3  sess_000003  user_002155  2021-03-19      mobile   Safari   Split   \n",
      "4  sess_000004  user_000349  2021-03-15      tablet  Firefox  Zagreb   \n",
      "\n",
      "              variant  is_registered  novelty_revenue  \\\n",
      "0  A_manual_novelties              1         6.611739   \n",
      "1  A_manual_novelties              1         2.508166   \n",
      "2  A_manual_novelties              1         3.860873   \n",
      "3  A_manual_novelties              1         5.869096   \n",
      "4  A_manual_novelties              0         1.404599   \n",
      "\n",
      "   products_added_from_novelties  \n",
      "0                              0  \n",
      "1                              0  \n",
      "2                              0  \n",
      "3                              0  \n",
      "4                              0  \n",
      "\n",
      "==================================================\n",
      "FILE: test3_product_sliders.csv\n",
      "==================================================\n",
      "    session_id      user_id   timestamp device_type  browser  region  \\\n",
      "0  sess_000000  user_000567  2021-03-31      mobile  Firefox  Zagreb   \n",
      "1  sess_000001  user_002296  2021-03-28     desktop   Safari  Zagreb   \n",
      "2  sess_000002  user_002093  2021-04-05     desktop   Safari  Rijeka   \n",
      "3  sess_000003  user_003489  2021-04-03     desktop   Safari  Osijek   \n",
      "4  sess_000004  user_000446  2021-03-29     desktop   Chrome   Split   \n",
      "\n",
      "                     variant  add_to_cart_rate  slider_interactions  \\\n",
      "0  A_selected_by_others_only                 0                    1   \n",
      "1  A_selected_by_others_only                 0                    4   \n",
      "2  A_selected_by_others_only                 0                    2   \n",
      "3  A_selected_by_others_only                 0                    2   \n",
      "4  A_selected_by_others_only                 0                    2   \n",
      "\n",
      "   revenue_from_recommendations  products_per_order  avg_product_price  \n",
      "0                      3.471560            3.096859           3.284346  \n",
      "1                      2.661356            3.533376           3.617489  \n",
      "2                      1.171862            2.662017           4.786812  \n",
      "3                      4.125438            3.888011           5.257324  \n",
      "4                      1.884486            2.126060           3.966839  \n",
      "\n",
      "==================================================\n",
      "FILE: test4_reviews.csv\n",
      "==================================================\n",
      "    session_id      user_id   timestamp device_type browser  region  \\\n",
      "0  sess_000000  user_001127  2021-04-11      mobile  Chrome   Other   \n",
      "1  sess_000001  user_006812  2021-05-02      mobile  Chrome  Rijeka   \n",
      "2  sess_000002  user_004380  2021-04-27      mobile  Chrome  Zagreb   \n",
      "3  sess_000003  user_009545  2021-04-29      mobile  Chrome  Zagreb   \n",
      "4  sess_000004  user_012102  2021-05-08      mobile  Chrome   Other   \n",
      "\n",
      "                 variant  converted  added_to_cart  \n",
      "0  A_no_featured_reviews        0.0              1  \n",
      "1  A_no_featured_reviews        0.0              1  \n",
      "2  A_no_featured_reviews        0.0              1  \n",
      "3  A_no_featured_reviews        0.0              1  \n",
      "4  A_no_featured_reviews        0.0              1  \n",
      "\n",
      "==================================================\n",
      "FILE: test5_search_engine.csv\n",
      "==================================================\n",
      "    session_id      user_id   timestamp device_type browser  region  \\\n",
      "0  sess_000000  user_001321  2021-06-13     desktop  Chrome   Other   \n",
      "1  sess_000001  user_000722  2021-06-17      mobile  Safari   Split   \n",
      "2  sess_000002  user_000665  2021-06-14      mobile  Chrome  Zagreb   \n",
      "3  sess_000003  user_002173  2021-06-14     desktop  Chrome   Other   \n",
      "4  sess_000004  user_001023  2021-06-13     desktop  Chrome   Other   \n",
      "\n",
      "           variant  avg_revenue_per_visitor  added_to_cart  converted  \\\n",
      "0  A_hybris_search                 1.066146              1          0   \n",
      "1  A_hybris_search                 0.817668              1          0   \n",
      "2  A_hybris_search                 1.341627              1          0   \n",
      "3  A_hybris_search                 1.389355              1          0   \n",
      "4  A_hybris_search                 0.285824              1          0   \n",
      "\n",
      "   interacted_with_search  \n",
      "0                       0  \n",
      "1                       0  \n",
      "2                       1  \n",
      "3                       1  \n",
      "4                       0  \n",
      "\n",
      "==================================================\n",
      "âœ… SUKSES! Semua dataframe (df1 - df5) siap digunakan.\n",
      "   df1 -> test1_menu.csv\n",
      "   df2 -> test2_novelty_slider.csv\n",
      "   df3 -> test3_product_sliders.csv\n",
      "   df4 -> test4_reviews.csv\n",
      "   df5 -> test5_search_engine.csv\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# 1. Setup Base Directory\n",
    "base_dir = os.path.join(os.getcwd(), 'raw_dataset')\n",
    "\n",
    "# 2. Daftar Nama File\n",
    "file_names = [\n",
    "    'test1_menu.csv',\n",
    "    'test2_novelty_slider.csv',\n",
    "    'test3_product_sliders.csv',\n",
    "    'test4_reviews.csv',\n",
    "    'test5_search_engine.csv'\n",
    "]\n",
    "\n",
    "# 3. Buat Path Lengkap\n",
    "paths = [os.path.join(base_dir, name) for name in file_names]\n",
    "\n",
    "# List penampung sementara\n",
    "loaded_dfs = []\n",
    "\n",
    "# 4. Loop untuk Membaca dan Menampilkan Data\n",
    "for path in paths:\n",
    "    if os.path.exists(path):\n",
    "        # Ambil nama file untuk judul\n",
    "        name = os.path.basename(path)\n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(f\"FILE: {name}\")\n",
    "        print(f\"{'='*50}\")\n",
    "        \n",
    "        try:\n",
    "            # Baca CSV\n",
    "            temp_df = pd.read_csv(path)\n",
    "            \n",
    "            # Tampilkan 5 baris pertama\n",
    "            print(temp_df.head())\n",
    "            \n",
    "            # Masukkan ke list penampung\n",
    "            loaded_dfs.append(temp_df)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Error saat membaca file: {e}\")\n",
    "    else:\n",
    "        print(f\"âš ï¸ Warning: File tidak ditemukan di {path}\")\n",
    "\n",
    "# 5. ASSIGN KE VARIABEL df1 - df5\n",
    "# Kita pastikan jumlah file yang terbaca pas 5 agar unpacking tidak error\n",
    "if len(loaded_dfs) == 5:\n",
    "    df1, df2, df3, df4, df5 = loaded_dfs\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(\"âœ… SUKSES! Semua dataframe (df1 - df5) siap digunakan.\")\n",
    "    print(\"   df1 -> test1_menu.csv\")\n",
    "    print(\"   df2 -> test2_novelty_slider.csv\")\n",
    "    print(\"   df3 -> test3_product_sliders.csv\")\n",
    "    print(\"   df4 -> test4_reviews.csv\")\n",
    "    print(\"   df5 -> test5_search_engine.csv\")\n",
    "    print(f\"{'='*50}\")\n",
    "else:\n",
    "    print(f\"\\nâš ï¸ PERINGATAN: Jumlah file yang terbaca ({len(loaded_dfs)}) tidak sesuai target (5). Variabel df1-df5 belum dibuat.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8377c452",
   "metadata": {},
   "source": [
    "### Metric Define"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "6c45dfdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def define_metric_flow_smart_v2(df, dataset_name=\"Dataset\"):\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"ðŸ•µï¸  SMART METRIC FLOW ANALYSIS (V2 - COMPLETE): {dataset_name}\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    try:\n",
    "        variant_col_index = df.columns.get_loc('variant')\n",
    "        metric_columns = df.columns[variant_col_index + 1:]\n",
    "        \n",
    "        # --- CHECK VARIANTS ---\n",
    "        unique_variants = df['variant'].unique()\n",
    "        num_variants = len(unique_variants)\n",
    "        print(f\"â„¹ï¸  Variant Info: Found {num_variants} types ({', '.join(unique_variants)})\")\n",
    "        \n",
    "        if num_variants > 2:\n",
    "            print(\"âš ï¸  NOTE: Variants > 2 -> Multi-Sample Tests.\")\n",
    "        else:\n",
    "            print(\"â„¹ï¸  NOTE: Variants = 2 -> Two-Sample Tests.\")\n",
    "        print(\"-\" * 70)\n",
    "        \n",
    "    except KeyError:\n",
    "        print(\"Error: Column 'variant' not found.\")\n",
    "        return\n",
    "\n",
    "    for metric in metric_columns:\n",
    "        # Bersihkan data\n",
    "        clean_data = df[metric].dropna()\n",
    "        unique_values = clean_data.unique()\n",
    "        dtype = clean_data.dtype\n",
    "        \n",
    "        # --- CLASSIFICATION LOGIC ---\n",
    "        \n",
    "        # 1. CATEGORICAL / NOMINAL (String/Object) -> BARU!\n",
    "        if dtype == 'object' or dtype.name == 'category':\n",
    "            metric_type = \"Categorical / Nominal\"\n",
    "            step_2 = \"Check Expected Frequencies > 5\"\n",
    "            step_3 = \"Chi-Square Test of Independence (All Variants)\"\n",
    "            \n",
    "        # 2. BINARY (0/1)\n",
    "        elif set(unique_values).issubset({0, 1, 0.0, 1.0}):\n",
    "            metric_type = \"Binary (0/1)\"\n",
    "            step_2 = \"Check Sample Size (np > 5)\"\n",
    "            \n",
    "            if num_variants > 2:\n",
    "                step_3 = \"Chi-Square Test (RxC Contingency)\"\n",
    "            else:\n",
    "                step_3 = \"Two-Sample Z-Test for Proportions\"\n",
    "            \n",
    "        # 3. COUNT (Based on Keywords)\n",
    "        elif any(keyword in metric for keyword in ['pages', 'products', 'items', 'clicks', 'interactions', 'slider']):\n",
    "            metric_type = \"Count (Business Logic Override)\"\n",
    "            step_2 = \"Consider Distribution (Poisson vs Neg. Binomial)\"\n",
    "            \n",
    "            if num_variants > 2:\n",
    "                step_3 = \"Kruskal-Wallis\"\n",
    "            else:\n",
    "                step_3 = \"Mann-Whitney U (or Poisson Test)\"\n",
    "            \n",
    "        # 4. CONTINUOUS (Based on Keywords)\n",
    "        elif any(keyword in metric for keyword in ['revenue', 'price', 'money', 'sales', 'time']):\n",
    "            metric_type = \"Continuous (Money/Real)\"\n",
    "            step_2 = \"Check Normality (Shapiro-Wilk)\"\n",
    "            \n",
    "            if num_variants > 2:\n",
    "                step_3 = \"One-Way ANOVA (Normal) OR Kruskal-Wallis (Skewed)\"\n",
    "            else:\n",
    "                step_3 = \"T-Test (Normal) OR Mann-Whitney U (Skewed)\"\n",
    "\n",
    "        # 5. COUNT (Based on Content - Fallback)\n",
    "        elif np.all(clean_data % 1 == 0):\n",
    "            metric_type = \"Count (Integer)\"\n",
    "            step_2 = \"Consider Distribution (Poisson vs Neg. Binomial)\"\n",
    "            \n",
    "            if num_variants > 2:\n",
    "                step_3 = \"Kruskal-Wallis\"\n",
    "            else:\n",
    "                step_3 = \"Mann-Whitney U\"\n",
    "                \n",
    "        # 6. CONTINUOUS (Based on Content - Fallback)\n",
    "        else:\n",
    "            metric_type = \"Continuous (Real Numbers)\"\n",
    "            step_2 = \"Check Normality (Shapiro-Wilk)\"\n",
    "            \n",
    "            if num_variants > 2:\n",
    "                step_3 = \"One-Way ANOVA (Normal) OR Kruskal-Wallis (Skewed)\"\n",
    "            else:\n",
    "                step_3 = \"T-Test (Normal) OR Mann-Whitney U (Skewed)\"\n",
    "\n",
    "        # Print Results\n",
    "        print(f\"Metric: {metric}\")\n",
    "        print(f\"   â””â”€â”€> Type:   {metric_type}\")\n",
    "        print(f\"   â””â”€â”€> Step 2: {step_2}\")\n",
    "        print(f\"   â””â”€â”€> Step 3: {step_3}\")\n",
    "        print(\"-\" * 70)\n",
    "\n",
    "# --- JALANKAN UNTUK MEMASTIKAN ---\n",
    "# dfs = [df1, df2, df3, df4, df5]\n",
    "# names = [\"Test 1\", \"Test 2\", \"Test 3\", \"Test 4\", \"Test 5\"]\n",
    "# for d, n in zip(dfs, names):\n",
    "#     define_metric_flow_smart_v2(d, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "ba112d44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "ðŸ•µï¸  SMART METRIC FLOW ANALYSIS (V2 - COMPLETE): TEST 1: Menu Design\n",
      "======================================================================\n",
      "â„¹ï¸  Variant Info: Found 2 types (A_horizontal_menu, B_dropdown_menu)\n",
      "â„¹ï¸  NOTE: Variants = 2 -> Two-Sample Tests.\n",
      "----------------------------------------------------------------------\n",
      "Metric: pages_viewed\n",
      "   â””â”€â”€> Type:   Count (Business Logic Override)\n",
      "   â””â”€â”€> Step 2: Consider Distribution (Poisson vs Neg. Binomial)\n",
      "   â””â”€â”€> Step 3: Mann-Whitney U (or Poisson Test)\n",
      "----------------------------------------------------------------------\n",
      "Metric: added_to_cart\n",
      "   â””â”€â”€> Type:   Binary (0/1)\n",
      "   â””â”€â”€> Step 2: Check Sample Size (np > 5)\n",
      "   â””â”€â”€> Step 3: Two-Sample Z-Test for Proportions\n",
      "----------------------------------------------------------------------\n",
      "Metric: bounced\n",
      "   â””â”€â”€> Type:   Binary (0/1)\n",
      "   â””â”€â”€> Step 2: Check Sample Size (np > 5)\n",
      "   â””â”€â”€> Step 3: Two-Sample Z-Test for Proportions\n",
      "----------------------------------------------------------------------\n",
      "Metric: revenue\n",
      "   â””â”€â”€> Type:   Continuous (Money/Real)\n",
      "   â””â”€â”€> Step 2: Check Normality (Shapiro-Wilk)\n",
      "   â””â”€â”€> Step 3: T-Test (Normal) OR Mann-Whitney U (Skewed)\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "ðŸ•µï¸  SMART METRIC FLOW ANALYSIS (V2 - COMPLETE): TEST 2: Novelty Slider\n",
      "======================================================================\n",
      "â„¹ï¸  Variant Info: Found 2 types (A_manual_novelties, B_personalized_novelties)\n",
      "â„¹ï¸  NOTE: Variants = 2 -> Two-Sample Tests.\n",
      "----------------------------------------------------------------------\n",
      "Metric: is_registered\n",
      "   â””â”€â”€> Type:   Binary (0/1)\n",
      "   â””â”€â”€> Step 2: Check Sample Size (np > 5)\n",
      "   â””â”€â”€> Step 3: Two-Sample Z-Test for Proportions\n",
      "----------------------------------------------------------------------\n",
      "Metric: novelty_revenue\n",
      "   â””â”€â”€> Type:   Continuous (Money/Real)\n",
      "   â””â”€â”€> Step 2: Check Normality (Shapiro-Wilk)\n",
      "   â””â”€â”€> Step 3: T-Test (Normal) OR Mann-Whitney U (Skewed)\n",
      "----------------------------------------------------------------------\n",
      "Metric: products_added_from_novelties\n",
      "   â””â”€â”€> Type:   Binary (0/1)\n",
      "   â””â”€â”€> Step 2: Check Sample Size (np > 5)\n",
      "   â””â”€â”€> Step 3: Two-Sample Z-Test for Proportions\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "ðŸ•µï¸  SMART METRIC FLOW ANALYSIS (V2 - COMPLETE): TEST 3: Product Sliders\n",
      "======================================================================\n",
      "â„¹ï¸  Variant Info: Found 3 types (A_selected_by_others_only, B_similar_products_top, C_selected_by_others_top)\n",
      "âš ï¸  NOTE: Variants > 2 -> Multi-Sample Tests.\n",
      "----------------------------------------------------------------------\n",
      "Metric: add_to_cart_rate\n",
      "   â””â”€â”€> Type:   Binary (0/1)\n",
      "   â””â”€â”€> Step 2: Check Sample Size (np > 5)\n",
      "   â””â”€â”€> Step 3: Chi-Square Test (RxC Contingency)\n",
      "----------------------------------------------------------------------\n",
      "Metric: slider_interactions\n",
      "   â””â”€â”€> Type:   Count (Business Logic Override)\n",
      "   â””â”€â”€> Step 2: Consider Distribution (Poisson vs Neg. Binomial)\n",
      "   â””â”€â”€> Step 3: Kruskal-Wallis\n",
      "----------------------------------------------------------------------\n",
      "Metric: revenue_from_recommendations\n",
      "   â””â”€â”€> Type:   Continuous (Money/Real)\n",
      "   â””â”€â”€> Step 2: Check Normality (Shapiro-Wilk)\n",
      "   â””â”€â”€> Step 3: One-Way ANOVA (Normal) OR Kruskal-Wallis (Skewed)\n",
      "----------------------------------------------------------------------\n",
      "Metric: products_per_order\n",
      "   â””â”€â”€> Type:   Count (Business Logic Override)\n",
      "   â””â”€â”€> Step 2: Consider Distribution (Poisson vs Neg. Binomial)\n",
      "   â””â”€â”€> Step 3: Kruskal-Wallis\n",
      "----------------------------------------------------------------------\n",
      "Metric: avg_product_price\n",
      "   â””â”€â”€> Type:   Continuous (Money/Real)\n",
      "   â””â”€â”€> Step 2: Check Normality (Shapiro-Wilk)\n",
      "   â””â”€â”€> Step 3: One-Way ANOVA (Normal) OR Kruskal-Wallis (Skewed)\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "ðŸ•µï¸  SMART METRIC FLOW ANALYSIS (V2 - COMPLETE): TEST 4: Reviews\n",
      "======================================================================\n",
      "â„¹ï¸  Variant Info: Found 2 types (A_no_featured_reviews, B_featured_reviews)\n",
      "â„¹ï¸  NOTE: Variants = 2 -> Two-Sample Tests.\n",
      "----------------------------------------------------------------------\n",
      "Metric: converted\n",
      "   â””â”€â”€> Type:   Binary (0/1)\n",
      "   â””â”€â”€> Step 2: Check Sample Size (np > 5)\n",
      "   â””â”€â”€> Step 3: Two-Sample Z-Test for Proportions\n",
      "----------------------------------------------------------------------\n",
      "Metric: added_to_cart\n",
      "   â””â”€â”€> Type:   Binary (0/1)\n",
      "   â””â”€â”€> Step 2: Check Sample Size (np > 5)\n",
      "   â””â”€â”€> Step 3: Two-Sample Z-Test for Proportions\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "ðŸ•µï¸  SMART METRIC FLOW ANALYSIS (V2 - COMPLETE): TEST 5: Search Engine\n",
      "======================================================================\n",
      "â„¹ï¸  Variant Info: Found 2 types (A_hybris_search, B_algolia_search)\n",
      "â„¹ï¸  NOTE: Variants = 2 -> Two-Sample Tests.\n",
      "----------------------------------------------------------------------\n",
      "Metric: avg_revenue_per_visitor\n",
      "   â””â”€â”€> Type:   Continuous (Money/Real)\n",
      "   â””â”€â”€> Step 2: Check Normality (Shapiro-Wilk)\n",
      "   â””â”€â”€> Step 3: T-Test (Normal) OR Mann-Whitney U (Skewed)\n",
      "----------------------------------------------------------------------\n",
      "Metric: added_to_cart\n",
      "   â””â”€â”€> Type:   Binary (0/1)\n",
      "   â””â”€â”€> Step 2: Check Sample Size (np > 5)\n",
      "   â””â”€â”€> Step 3: Two-Sample Z-Test for Proportions\n",
      "----------------------------------------------------------------------\n",
      "Metric: converted\n",
      "   â””â”€â”€> Type:   Binary (0/1)\n",
      "   â””â”€â”€> Step 2: Check Sample Size (np > 5)\n",
      "   â””â”€â”€> Step 3: Two-Sample Z-Test for Proportions\n",
      "----------------------------------------------------------------------\n",
      "Metric: interacted_with_search\n",
      "   â””â”€â”€> Type:   Binary (0/1)\n",
      "   â””â”€â”€> Step 2: Check Sample Size (np > 5)\n",
      "   â””â”€â”€> Step 3: Two-Sample Z-Test for Proportions\n",
      "----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# --- EXECUTION EXAMPLE (UN-COMMENT BELOW TO RUN) ---\n",
    "dfs = [df1, df2, df3, df4, df5]\n",
    "names = [\n",
    "    \"TEST 1: Menu Design\", \n",
    "    \"TEST 2: Novelty Slider\", \n",
    "    \"TEST 3: Product Sliders\", \n",
    "    \"TEST 4: Reviews\", \n",
    "    \"TEST 5: Search Engine\"\n",
    "]\n",
    "\n",
    "for d, n in zip(dfs, names):\n",
    "    define_metric_flow_smart_v2(d, n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e210a328",
   "metadata": {},
   "source": [
    "### Statistic step define"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "256f8fd5",
   "metadata": {},
   "source": [
    "#### count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90104550",
   "metadata": {},
   "source": [
    "- For count category with 2 or >2 variants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "212f4559",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import itertools\n",
    "\n",
    "def poisson_two_sample_test(count_a, n_a, count_b, n_b):\n",
    "    \"\"\"\n",
    "    Manual implementation of Two-Sample Poisson Rate Test (Wald Test)\n",
    "    H0: Rate A = Rate B\n",
    "    \"\"\"\n",
    "    rate_a = count_a / n_a\n",
    "    rate_b = count_b / n_b\n",
    "    pooled_rate = (count_a + count_b) / (n_a + n_b)\n",
    "    se = np.sqrt(pooled_rate * (1/n_a + 1/n_b))\n",
    "    z = (rate_a - rate_b) / se\n",
    "    p_value = 2 * (1 - stats.norm.cdf(abs(z)))\n",
    "    return z, p_value\n",
    "\n",
    "def analyze_count_metric_strict(df, metric_column, variant_column='variant', control_variant=None, alpha=0.05):\n",
    "    \"\"\"\n",
    "    STRICT Count Analysis Function.\n",
    "    - control_variant: Specifies the baseline group to ensure correct Lift calculation.\n",
    "    - alpha: Significance threshold for tests and post-hoc.\n",
    "    \"\"\"\n",
    "    \n",
    "    # 0. DATA PREPARATION & SORTING\n",
    "    raw_variants = df[variant_column].unique()\n",
    "    \n",
    "    # --- LOGIKA PENENTUAN CONTROL ---\n",
    "    if control_variant is None:\n",
    "        unique_variants = sorted(raw_variants)\n",
    "        control_variant = unique_variants[0]\n",
    "        print(f\"â„¹ï¸  Note: No control specified. Using '{control_variant}' as Control (Alphabetical default).\")\n",
    "    else:\n",
    "        if control_variant not in raw_variants:\n",
    "            print(f\"âŒ Error: Variant '{control_variant}' not found in dataset!\")\n",
    "            return\n",
    "        # Reorder: Control index 0, others follow\n",
    "        others = sorted([v for v in raw_variants if v != control_variant])\n",
    "        unique_variants = [control_variant] + others\n",
    "\n",
    "    num_variants = len(unique_variants)\n",
    "    \n",
    "    # Extract data sesuai urutan yang sudah diperbaiki\n",
    "    groups = []\n",
    "    group_names = []\n",
    "    for v in unique_variants:\n",
    "        data = df[df[variant_column] == v][metric_column].dropna()\n",
    "        groups.append(data)\n",
    "        group_names.append(v)\n",
    "\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"ðŸ“Š STRICT COUNT ANALYSIS: {metric_column}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"â„¹ï¸  Info: Found {num_variants} Variants\")\n",
    "    print(f\"â„¹ï¸  Control Group: '{group_names[0]}'\")\n",
    "    print(f\"â„¹ï¸  Settings: Alpha Threshold = {alpha}\")\n",
    "\n",
    "    # [STEP 1] IDENTIFY\n",
    "    print(\"\\n[STEP 1] Metric Type: Count Data (Integer)\")\n",
    "\n",
    "    # [STEP 2] CHECK DISTRIBUTION\n",
    "    print(\"\\n[STEP 2] Checking Distribution (Dispersion Check)\")\n",
    "    ctrl_data = groups[0]\n",
    "    mean_val = ctrl_data.mean()\n",
    "    var_val = ctrl_data.var()\n",
    "    \n",
    "    if mean_val == 0: ratio = 0\n",
    "    else: ratio = var_val / mean_val\n",
    "    \n",
    "    print(f\"   -> Mean: {mean_val:.4f} | Variance: {var_val:.4f}\")\n",
    "    print(f\"   -> Ratio: {ratio:.2f}x\")\n",
    "    \n",
    "    # LOGIC BRANCHING\n",
    "    if ratio > 1.5:\n",
    "        is_poisson = False\n",
    "        dist_status = \"Overdispersed (Negative Binomial)\"\n",
    "        decision = \"Data is skewed/high variance. Using Non-Parametric Test.\"\n",
    "    else:\n",
    "        is_poisson = True\n",
    "        dist_status = \"Poisson / Underdispersed\"\n",
    "        decision = \"Data is stable (Poisson). Using Poisson Rate Test.\"\n",
    "        \n",
    "    print(f\"   -> Diagnosis: {dist_status}\")\n",
    "    print(f\"   -> Decision:  {decision}\")\n",
    "\n",
    "    # [STEP 3] EXECUTE TEST\n",
    "    print(f\"\\n[STEP 3] Executing Test...\")\n",
    "    \n",
    "    # --- CASE A: 2 VARIANTS ---\n",
    "    if num_variants == 2:\n",
    "        if is_poisson:\n",
    "            # JALUR POISSON\n",
    "            test_name = \"Two-Sample Poisson Test (Wald)\"\n",
    "            sum_a, n_a = groups[0].sum(), len(groups[0])\n",
    "            sum_b, n_b = groups[1].sum(), len(groups[1])\n",
    "            stat, p_value = poisson_two_sample_test(sum_a, n_a, sum_b, n_b)\n",
    "        else:\n",
    "            # JALUR NEG. BINOMIAL\n",
    "            test_name = \"Mann-Whitney U Test\"\n",
    "            stat, p_value = stats.mannwhitneyu(groups[0], groups[1], alternative='two-sided')\n",
    "            \n",
    "        print(f\"   -> Selected Test: {test_name}\")\n",
    "        \n",
    "        # Calculate Lift (Correctly using Index 0 as Control)\n",
    "        mean_ctrl = groups[0].mean()\n",
    "        mean_trt = groups[1].mean()\n",
    "        lift = (mean_trt - mean_ctrl) / mean_ctrl * 100 if mean_ctrl != 0 else 0\n",
    "        \n",
    "        print(f\"   -> Mean ({group_names[0]}): {mean_ctrl:.4f} [Control]\")\n",
    "        print(f\"   -> Mean ({group_names[1]}): {mean_trt:.4f} [Treatment]\")\n",
    "        print(f\"   -> Lift: {lift:+.2f}%\")\n",
    "        print(f\"   -> P-Value: {p_value:.5f}\")\n",
    "\n",
    "    # --- CASE B: > 2 VARIANTS ---\n",
    "    else:\n",
    "        # Kruskal-Wallis is the standard fallback for >2 variants\n",
    "        test_name = \"Kruskal-Wallis H Test\"\n",
    "        stat, p_value = stats.kruskal(*groups)\n",
    "            \n",
    "        print(f\"   -> Selected Test: {test_name}\")\n",
    "        print(f\"   -> P-Value: {p_value:.5f}\")\n",
    "        \n",
    "        # --- POST-HOC LOGIC ---\n",
    "        if p_value < alpha:\n",
    "            print(f\"\\n   [POST-HOC ANALYSIS - ALPHA {alpha}]\")\n",
    "            print(\"   -> Checking pairwise differences...\")\n",
    "            \n",
    "            pairs = list(itertools.combinations(range(num_variants), 2))\n",
    "            \n",
    "            for i, j in pairs:\n",
    "                # Use Mann-Whitney for pairwise comparison\n",
    "                _, p_pair = stats.mannwhitneyu(groups[i], groups[j], alternative='two-sided')\n",
    "                \n",
    "                # Compare against the dynamic Alpha\n",
    "                sig = \"âœ… DIFF\" if p_pair < alpha else \"âŒ SAME\"\n",
    "                \n",
    "                # Show diff for context\n",
    "                diff_val = groups[j].mean() - groups[i].mean()\n",
    "                \n",
    "                print(f\"      â€¢ {group_names[i]} vs {group_names[j]}\")\n",
    "                print(f\"        -> Diff: {diff_val:.4f} | p={p_pair:.5f} -> {sig}\")\n",
    "        else:\n",
    "             print(\"\\n   [POST-HOC ANALYSIS]\")\n",
    "             print(\"   -> Skipped because Global Test was NOT significant.\")\n",
    "\n",
    "    # CONCLUSION\n",
    "    print(f\"\\n[CONCLUSION] Threshold: {alpha}\")\n",
    "    if p_value < alpha:\n",
    "        print(f\"âœ… SIGNIFICANT. ({test_name} rejected H0).\")\n",
    "    else:\n",
    "        print(f\"âŒ NOT SIGNIFICANT. ({test_name} failed to reject H0).\")\n",
    "    \n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "e6217037",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â„¹ï¸  Note: No control specified. Using 'A_horizontal_menu' as Control (Alphabetical default).\n",
      "\n",
      "================================================================================\n",
      "ðŸ“Š STRICT COUNT ANALYSIS: pages_viewed\n",
      "================================================================================\n",
      "â„¹ï¸  Info: Found 2 Variants\n",
      "â„¹ï¸  Control Group: 'A_horizontal_menu'\n",
      "â„¹ï¸  Settings: Alpha Threshold = 0.05\n",
      "\n",
      "[STEP 1] Metric Type: Count Data (Integer)\n",
      "\n",
      "[STEP 2] Checking Distribution (Dispersion Check)\n",
      "   -> Mean: 2.1944 | Variance: 0.5936\n",
      "   -> Ratio: 0.27x\n",
      "   -> Diagnosis: Poisson / Underdispersed\n",
      "   -> Decision:  Data is stable (Poisson). Using Poisson Rate Test.\n",
      "\n",
      "[STEP 3] Executing Test...\n",
      "   -> Selected Test: Two-Sample Poisson Test (Wald)\n",
      "   -> Mean (A_horizontal_menu): 2.1944 [Control]\n",
      "   -> Mean (B_dropdown_menu): 2.1504 [Treatment]\n",
      "   -> Lift: -2.01%\n",
      "   -> P-Value: 0.21171\n",
      "\n",
      "[CONCLUSION] Threshold: 0.05\n",
      "âŒ NOT SIGNIFICANT. (Two-Sample Poisson Test (Wald) failed to reject H0).\n",
      "--------------------------------------------------------------------------------\n",
      "â„¹ï¸  Note: No control specified. Using 'A_selected_by_others_only' as Control (Alphabetical default).\n",
      "\n",
      "================================================================================\n",
      "ðŸ“Š STRICT COUNT ANALYSIS: products_per_order\n",
      "================================================================================\n",
      "â„¹ï¸  Info: Found 3 Variants\n",
      "â„¹ï¸  Control Group: 'A_selected_by_others_only'\n",
      "â„¹ï¸  Settings: Alpha Threshold = 0.05\n",
      "\n",
      "[STEP 1] Metric Type: Count Data (Integer)\n",
      "\n",
      "[STEP 2] Checking Distribution (Dispersion Check)\n",
      "   -> Mean: 3.1563 | Variance: 0.7916\n",
      "   -> Ratio: 0.25x\n",
      "   -> Diagnosis: Poisson / Underdispersed\n",
      "   -> Decision:  Data is stable (Poisson). Using Poisson Rate Test.\n",
      "\n",
      "[STEP 3] Executing Test...\n",
      "   -> Selected Test: Kruskal-Wallis H Test\n",
      "   -> P-Value: 0.00000\n",
      "\n",
      "   [POST-HOC ANALYSIS - ALPHA 0.05]\n",
      "   -> Checking pairwise differences...\n",
      "      â€¢ A_selected_by_others_only vs B_similar_products_top\n",
      "        -> Diff: -0.1112 | p=0.00000 -> âœ… DIFF\n",
      "      â€¢ A_selected_by_others_only vs C_selected_by_others_top\n",
      "        -> Diff: -0.0576 | p=0.00047 -> âœ… DIFF\n",
      "      â€¢ B_similar_products_top vs C_selected_by_others_top\n",
      "        -> Diff: 0.0536 | p=0.00252 -> âœ… DIFF\n",
      "\n",
      "[CONCLUSION] Threshold: 0.05\n",
      "âœ… SIGNIFICANT. (Kruskal-Wallis H Test rejected H0).\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 1. TES LOGIKA 2 VARIAN (Dataset Menu)\n",
    "# Kita tes kolom 'pages_viewed'\n",
    "# atau secara eksplisit:\n",
    "analyze_count_metric_strict(df1, 'pages_viewed', alpha=0.05)\n",
    "\n",
    "# 2. TES LOGIKA 3 VARIAN (Dataset Product Sliders - df3)\n",
    "# Kita asumsikan df3 sudah diload. Kolom 'products_added' biasanya Count.\n",
    "# Pastikan nama kolomnya benar (cek df3.head() dulu kalau ragu)\n",
    "if 'products_per_order' in df3.columns: # Ganti nama kolom sesuai data asli df3\n",
    "    analyze_count_metric_strict(df3, 'products_per_order')\n",
    "else:\n",
    "    # Cari nama kolom yang mirip count di df3\n",
    "    print(\"Kolom products_per_order tidak ditemukan, coba cek nama kolom di df3.\")\n",
    "    print(df3.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a5de30e",
   "metadata": {},
   "source": [
    "#### continuos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "1ac8c5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import itertools\n",
    "\n",
    "def analyze_continuous_metric_strict(df, metric_column, variant_column='variant', control_variant=None, alpha=0.05):\n",
    "    \"\"\"\n",
    "    STRICT Continuous Analysis Function.\n",
    "    - control_variant: Name of the control group (string). Prevents inverted Lift calculation.\n",
    "    - Alpha input controls significance threshold.\n",
    "    \"\"\"\n",
    "    \n",
    "    # 0. DATA PREPARATION & SORTING\n",
    "    raw_variants = df[variant_column].unique()\n",
    "    \n",
    "    # --- LOGIKA PENENTUAN CONTROL (Supaya Lift Gak Kebalik) ---\n",
    "    if control_variant is None:\n",
    "        unique_variants = sorted(raw_variants)\n",
    "        control_variant = unique_variants[0]\n",
    "        print(f\"â„¹ï¸  Note: No control specified. Using '{control_variant}' as Control (Alphabetical default).\")\n",
    "    else:\n",
    "        if control_variant not in raw_variants:\n",
    "            print(f\"âŒ Error: Variant '{control_variant}' not found in dataset!\")\n",
    "            return\n",
    "        # Reorder: Control index 0, others follow\n",
    "        others = sorted([v for v in raw_variants if v != control_variant])\n",
    "        unique_variants = [control_variant] + others\n",
    "\n",
    "    num_variants = len(unique_variants)\n",
    "    \n",
    "    # Extract data sesuai urutan yang sudah diperbaiki\n",
    "    groups = []\n",
    "    group_names = []\n",
    "    for v in unique_variants:\n",
    "        data = df[df[variant_column] == v][metric_column].dropna()\n",
    "        groups.append(data)\n",
    "        group_names.append(v)\n",
    "\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"ðŸ’° STRICT CONTINUOUS ANALYSIS: {metric_column}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"â„¹ï¸  Info: Found {num_variants} Variants\")\n",
    "    print(f\"â„¹ï¸  Control Group: '{group_names[0]}'\")\n",
    "    print(f\"â„¹ï¸  Settings: Alpha = {alpha}\")\n",
    "\n",
    "    # [STEP 1] IDENTIFY\n",
    "    print(\"\\n[STEP 1] Metric Type: Continuous Data (Real Numbers)\")\n",
    "\n",
    "    # [STEP 2] CHECK DISTRIBUTION (NORMALITY CHECK)\n",
    "    print(\"\\n[STEP 2] Checking Distribution (Shapiro-Wilk Test)\")\n",
    "    \n",
    "    all_normal = True\n",
    "    for name, data in zip(group_names, groups):\n",
    "        if len(data) < 3:\n",
    "            print(f\"   -> {name}: Too few samples to test normality.\")\n",
    "            all_normal = False\n",
    "            break\n",
    "            \n",
    "        stat, p_shapiro = stats.shapiro(data)\n",
    "        is_norm = \"âœ… Normal\" if p_shapiro > 0.05 else \"âŒ Skewed\"\n",
    "        print(f\"   -> {name}: p={p_shapiro:.5f} -> {is_norm}\")\n",
    "        \n",
    "        if p_shapiro < 0.05:\n",
    "            all_normal = False\n",
    "    \n",
    "    if all_normal:\n",
    "        use_parametric = True\n",
    "        dist_status = \"Normal Distribution\"\n",
    "        decision = \"Data is Normal. SAFE to use Parametric Test (T-Test/ANOVA).\"\n",
    "    else:\n",
    "        use_parametric = False\n",
    "        dist_status = \"Skewed / Non-Normal Distribution\"\n",
    "        decision = \"Data is Skewed. MUST use Non-Parametric Test.\"\n",
    "        \n",
    "    print(f\"   -> Final Diagnosis: {dist_status}\")\n",
    "    print(f\"   -> Decision: {decision}\")\n",
    "\n",
    "    # [STEP 3] EXECUTE TEST\n",
    "    print(f\"\\n[STEP 3] Executing Test...\")\n",
    "    \n",
    "    # --- CASE A: 2 VARIANTS ---\n",
    "    if num_variants == 2:\n",
    "        if use_parametric:\n",
    "            test_name = \"Two-Sample T-Test (Welch's)\"\n",
    "            stat, p_value = stats.ttest_ind(groups[0], groups[1], equal_var=False)\n",
    "        else:\n",
    "            test_name = \"Mann-Whitney U Test\"\n",
    "            stat, p_value = stats.mannwhitneyu(groups[0], groups[1], alternative='two-sided')\n",
    "            \n",
    "        print(f\"   -> Selected Test: {test_name}\")\n",
    "        \n",
    "        # Calculate Lift (Correctly using Index 0 as Control)\n",
    "        mean_ctrl = groups[0].mean()\n",
    "        mean_trt = groups[1].mean()\n",
    "        lift = (mean_trt - mean_ctrl) / mean_ctrl * 100 if mean_ctrl != 0 else 0\n",
    "        \n",
    "        print(f\"   -> Mean ({group_names[0]}): {mean_ctrl:.4f} [Control]\")\n",
    "        print(f\"   -> Mean ({group_names[1]}): {mean_trt:.4f} [Treatment]\")\n",
    "        print(f\"   -> Lift: {lift:+.2f}%\")\n",
    "        print(f\"   -> P-Value: {p_value:.5f}\")\n",
    "\n",
    "    # --- CASE B: > 2 VARIANTS ---\n",
    "    else:\n",
    "        if use_parametric:\n",
    "            test_name = \"One-Way ANOVA\"\n",
    "            stat, p_value = stats.f_oneway(*groups)\n",
    "        else:\n",
    "            test_name = \"Kruskal-Wallis H Test\"\n",
    "            stat, p_value = stats.kruskal(*groups)\n",
    "            \n",
    "        print(f\"   -> Selected Test: {test_name}\")\n",
    "        print(f\"   -> P-Value: {p_value:.5f}\")\n",
    "        \n",
    "        # --- POST-HOC LOGIC ---\n",
    "        if p_value < alpha:\n",
    "            print(f\"\\n   [POST-HOC ANALYSIS - ALPHA {alpha}]\")\n",
    "            pairs = list(itertools.combinations(range(num_variants), 2))\n",
    "            \n",
    "            for i, j in pairs:\n",
    "                if use_parametric:\n",
    "                    _, p_pair = stats.ttest_ind(groups[i], groups[j], equal_var=False)\n",
    "                    test_type = \"T-Test\"\n",
    "                else:\n",
    "                    _, p_pair = stats.mannwhitneyu(groups[i], groups[j], alternative='two-sided')\n",
    "                    test_type = \"Mann-Whitney\"\n",
    "                \n",
    "                sig = \"âœ… DIFF\" if p_pair < alpha else \"âŒ SAME\"\n",
    "                \n",
    "                # Show differences in means just for context\n",
    "                diff_val = groups[j].mean() - groups[i].mean()\n",
    "                \n",
    "                print(f\"      â€¢ {group_names[i]} vs {group_names[j]} ({test_type})\")\n",
    "                print(f\"        -> Diff: {diff_val:.4f} | p={p_pair:.5f} -> {sig}\")\n",
    "        else:\n",
    "             print(\"\\n   [POST-HOC ANALYSIS]\")\n",
    "             print(\"   -> Skipped because Global Test was NOT significant.\")\n",
    "\n",
    "    # CONCLUSION\n",
    "    print(f\"\\n[CONCLUSION] Threshold: {alpha}\")\n",
    "    if p_value < alpha:\n",
    "        print(f\"âœ… SIGNIFICANT. ({test_name} rejected H0).\")\n",
    "    else:\n",
    "        print(f\"âŒ NOT SIGNIFICANT. ({test_name} failed to reject H0).\")\n",
    "    \n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "d79296ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â„¹ï¸  Note: No control specified. Using 'A_selected_by_others_only' as Control (Alphabetical default).\n",
      "\n",
      "================================================================================\n",
      "ðŸ’° STRICT CONTINUOUS ANALYSIS: revenue_from_recommendations\n",
      "================================================================================\n",
      "â„¹ï¸  Info: Found 3 Variants\n",
      "â„¹ï¸  Control Group: 'A_selected_by_others_only'\n",
      "â„¹ï¸  Settings: Alpha = 0.001\n",
      "\n",
      "[STEP 1] Metric Type: Continuous Data (Real Numbers)\n",
      "\n",
      "[STEP 2] Checking Distribution (Shapiro-Wilk Test)\n",
      "   -> A_selected_by_others_only: p=0.00000 -> âŒ Skewed\n",
      "   -> B_similar_products_top: p=0.00000 -> âŒ Skewed\n",
      "   -> C_selected_by_others_top: p=0.00000 -> âŒ Skewed\n",
      "   -> Final Diagnosis: Skewed / Non-Normal Distribution\n",
      "   -> Decision: Data is Skewed. MUST use Non-Parametric Test.\n",
      "\n",
      "[STEP 3] Executing Test...\n",
      "   -> Selected Test: Kruskal-Wallis H Test\n",
      "   -> P-Value: 0.00000\n",
      "\n",
      "   [POST-HOC ANALYSIS - ALPHA 0.001]\n",
      "      â€¢ A_selected_by_others_only vs B_similar_products_top (Mann-Whitney)\n",
      "        -> Diff: 0.9027 | p=0.00000 -> âœ… DIFF\n",
      "      â€¢ A_selected_by_others_only vs C_selected_by_others_top (Mann-Whitney)\n",
      "        -> Diff: 0.2151 | p=0.00007 -> âœ… DIFF\n",
      "      â€¢ B_similar_products_top vs C_selected_by_others_top (Mann-Whitney)\n",
      "        -> Diff: -0.6876 | p=0.00000 -> âœ… DIFF\n",
      "\n",
      "[CONCLUSION] Threshold: 0.001\n",
      "âœ… SIGNIFICANT. (Kruskal-Wallis H Test rejected H0).\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pijar2000\\AppData\\Local\\Temp\\ipykernel_21736\\2121774899.py:59: UserWarning: scipy.stats.shapiro: For N > 5000, computed p-value may not be accurate. Current N is 6000.\n",
      "  stat, p_shapiro = stats.shapiro(data)\n"
     ]
    }
   ],
   "source": [
    "# Panggil fungsi seperti biasa, tapi tambahkan alpha di belakangnya\n",
    "analyze_continuous_metric_strict(df3, 'revenue_from_recommendations', alpha=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "22cb11a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "ðŸ’° STRICT CONTINUOUS ANALYSIS: revenue\n",
      "================================================================================\n",
      "â„¹ï¸  Info: Found 2 Variants -> A_horizontal_menu, B_dropdown_menu\n",
      "\n",
      "[STEP 1] Metric Type: Continuous Data (Real Numbers)\n",
      "\n",
      "[STEP 2] Checking Distribution (Shapiro-Wilk Test)\n",
      "   -> A_horizontal_menu: p=0.00000 -> âŒ Skewed\n",
      "   -> B_dropdown_menu: p=0.00000 -> âŒ Skewed\n",
      "   -> Final Diagnosis: Skewed / Non-Normal Distribution\n",
      "   -> Decision: Data is Skewed. MUST use Non-Parametric Test.\n",
      "\n",
      "[STEP 3] Executing Test...\n",
      "   -> Selected Test: Mann-Whitney U Test\n",
      "   -> Mean Control: 3.4946\n",
      "   -> Mean Treatment: 3.1272\n",
      "   -> P-Value: 0.00000\n",
      "   -> Lift: -10.51%\n",
      "\n",
      "[CONCLUSION] Using Alpha Threshold: 0.05\n",
      "âœ… SIGNIFICANT. (Mann-Whitney U Test rejected H0).\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Contoh: Analisis Revenue di df1\n",
    "analyze_continuous_metric_strict(df1, 'revenue', alpha=0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b3124eb",
   "metadata": {},
   "source": [
    "#### binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "44ea1c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from statsmodels.stats.proportion import proportions_ztest\n",
    "import itertools\n",
    "\n",
    "def analyze_binary_metric_strict(df, metric_column, variant_column='variant', control_variant=None, alpha=0.05):\n",
    "    \"\"\"\n",
    "    STRICT Binary Analysis Function.\n",
    "    - control_variant: Name of the control group (string). If None, uses alphabetical first.\n",
    "    - Alpha input controls significance threshold.\n",
    "    \"\"\"\n",
    "    \n",
    "    # 0. DATA PREPARATION & SORTING\n",
    "    raw_variants = df[variant_column].unique()\n",
    "    \n",
    "    # --- LOGIKA PENENTUAN CONTROL ---\n",
    "    if control_variant is None:\n",
    "        # Kalau user tidak kasih tau, kita urutkan abjad (Default)\n",
    "        unique_variants = sorted(raw_variants)\n",
    "        control_variant = unique_variants[0] # Ambil yang pertama\n",
    "        print(f\"â„¹ï¸  Note: No control specified. Using '{control_variant}' as Control (Alphabetical default).\")\n",
    "    else:\n",
    "        # Kalau user kasih tau, kita pastikan nama itu ada\n",
    "        if control_variant not in raw_variants:\n",
    "            print(f\"âŒ Error: Variant '{control_variant}' not found in dataset!\")\n",
    "            print(f\"   Available variants: {raw_variants}\")\n",
    "            return\n",
    "        \n",
    "        # Kita susun ulang: Control ditaruh paling depan (index 0), sisanya mengikuti\n",
    "        others = sorted([v for v in raw_variants if v != control_variant])\n",
    "        unique_variants = [control_variant] + others\n",
    "\n",
    "    num_variants = len(unique_variants)\n",
    "    \n",
    "    # Hitung Sukses & Total per Varian (Sesuai urutan di atas)\n",
    "    successes = []\n",
    "    nobs = []\n",
    "    variant_names = []\n",
    "    \n",
    "    for v in unique_variants:\n",
    "        subset = df[df[variant_column] == v][metric_column]\n",
    "        successes.append(subset.sum())\n",
    "        nobs.append(subset.count())\n",
    "        variant_names.append(v)\n",
    "\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"âš–ï¸  STRICT BINARY ANALYSIS: {metric_column}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"â„¹ï¸  Info: Found {num_variants} Variants\")\n",
    "    print(f\"â„¹ï¸  Control Group: '{variant_names[0]}'\") # Pasti Index 0 karena sudah kita susun\n",
    "    print(f\"â„¹ï¸  Settings: Alpha = {alpha}\")\n",
    "\n",
    "    # [STEP 1] IDENTIFY\n",
    "    print(\"\\n[STEP 1] Metric Type: Binary Data (0/1)\")\n",
    "\n",
    "    # [STEP 2] CHECK ASSUMPTIONS\n",
    "    print(\"\\n[STEP 2] Checking Assumptions (Sample Size)\")\n",
    "    valid_sample = True\n",
    "    for s, n, name in zip(successes, nobs, variant_names):\n",
    "        if s < 5 or (n - s) < 5:\n",
    "            print(f\"   âš ï¸ Warning: {name} has too few samples (< 5). Results might be unstable.\")\n",
    "            valid_sample = False\n",
    "    \n",
    "    if valid_sample: print(\"   -> Status: Sample size is sufficient.\")\n",
    "    else: print(\"   -> Status: Proceed with caution.\")\n",
    "\n",
    "    # [STEP 3] EXECUTE TEST\n",
    "    print(f\"\\n[STEP 3] Executing Test...\")\n",
    "    \n",
    "    # --- CASE A: 2 VARIANTS (Z-TEST) ---\n",
    "    if num_variants == 2:\n",
    "        test_name = \"Two-Sample Z-Test for Proportions\"\n",
    "        \n",
    "        # statsmodels butuh array successes dan nobs\n",
    "        stat, p_value = proportions_ztest(successes, nobs)\n",
    "        \n",
    "        print(f\"   -> Selected Test: {test_name}\")\n",
    "        \n",
    "        # Calculate Rates\n",
    "        rate_ctrl = successes[0] / nobs[0]\n",
    "        rate_trt = successes[1] / nobs[1]\n",
    "        \n",
    "        # Lift Rumus: (Baru - Lama) / Lama\n",
    "        lift = (rate_trt - rate_ctrl) / rate_ctrl * 100 if rate_ctrl != 0 else 0\n",
    "        \n",
    "        # Print dengan NAMA ASLI biar gak bingung\n",
    "        print(f\"   -> Rate ({variant_names[0]}): {rate_ctrl:.4%} [Control]\")\n",
    "        print(f\"   -> Rate ({variant_names[1]}): {rate_trt:.4%} [Treatment]\")\n",
    "        print(f\"   -> Lift: {lift:+.2f}%\")\n",
    "        print(f\"   -> P-Value: {p_value:.5f}\")\n",
    "\n",
    "    # --- CASE B: > 2 VARIANTS (CHI-SQUARE) ---\n",
    "    else:\n",
    "        test_name = \"Chi-Square Test of Independence\"\n",
    "        \n",
    "        observed = []\n",
    "        for s, n in zip(successes, nobs):\n",
    "            observed.append([s, n - s])\n",
    "            \n",
    "        stat, p_value, dof, expected = stats.chi2_contingency(observed)\n",
    "            \n",
    "        print(f\"   -> Selected Test: {test_name}\")\n",
    "        print(f\"   -> P-Value: {p_value:.5f}\")\n",
    "        \n",
    "        # --- POST-HOC LOGIC ---\n",
    "        if p_value < alpha:\n",
    "            print(f\"\\n   [POST-HOC ANALYSIS - ALPHA {alpha}]\")\n",
    "            # Bandingkan semua varian terhadap Control (Index 0)\n",
    "            # Atau bandingkan antar semua pasangan? Biasanya antar pasangan.\n",
    "            \n",
    "            pairs = list(itertools.combinations(range(num_variants), 2))\n",
    "            \n",
    "            for i, j in pairs:\n",
    "                # Pairwise Z-Test\n",
    "                count = np.array([successes[i], successes[j]])\n",
    "                nobs_pair = np.array([nobs[i], nobs[j]])\n",
    "                \n",
    "                _, p_pair = proportions_ztest(count, nobs_pair)\n",
    "                \n",
    "                sig = \"âœ… DIFF\" if p_pair < alpha else \"âŒ SAME\"\n",
    "                \n",
    "                rate_i = successes[i] / nobs[i]\n",
    "                rate_j = successes[j] / nobs[j]\n",
    "                \n",
    "                # Biar jelas mana yang Control di pair ini\n",
    "                name_i = variant_names[i]\n",
    "                name_j = variant_names[j]\n",
    "                \n",
    "                print(f\"      â€¢ {name_i} ({rate_i:.1%}) vs {name_j} ({rate_j:.1%})\")\n",
    "                print(f\"        -> p={p_pair:.5f} -> {sig}\")\n",
    "        else:\n",
    "             print(\"\\n   [POST-HOC ANALYSIS]\")\n",
    "             print(\"   -> Skipped because Global Test was NOT significant.\")\n",
    "\n",
    "    # CONCLUSION\n",
    "    print(f\"\\n[CONCLUSION] Threshold: {alpha}\")\n",
    "    if p_value < alpha:\n",
    "        print(f\"âœ… SIGNIFICANT. ({test_name} rejected H0).\")\n",
    "    else:\n",
    "        print(f\"âŒ NOT SIGNIFICANT. ({test_name} failed to reject H0).\")\n",
    "    \n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "a38f97c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â„¹ï¸  Note: No control specified. Using 'A_horizontal_menu' as Control (Alphabetical default).\n",
      "\n",
      "================================================================================\n",
      "âš–ï¸  STRICT BINARY ANALYSIS: added_to_cart\n",
      "================================================================================\n",
      "â„¹ï¸  Info: Found 2 Variants\n",
      "â„¹ï¸  Control Group: 'A_horizontal_menu'\n",
      "â„¹ï¸  Settings: Alpha = 0.05\n",
      "\n",
      "[STEP 1] Metric Type: Binary Data (0/1)\n",
      "\n",
      "[STEP 2] Checking Assumptions (Sample Size)\n",
      "   -> Status: Sample size is sufficient.\n",
      "\n",
      "[STEP 3] Executing Test...\n",
      "   -> Selected Test: Two-Sample Z-Test for Proportions\n",
      "   -> Rate (A_horizontal_menu): 96.1714% [Control]\n",
      "   -> Rate (B_dropdown_menu): 86.2286% [Treatment]\n",
      "   -> Lift: -10.34%\n",
      "   -> P-Value: 0.00000\n",
      "\n",
      "[CONCLUSION] Threshold: 0.05\n",
      "âœ… SIGNIFICANT. (Two-Sample Z-Test for Proportions rejected H0).\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Analisis apakah Menu Baru meningkatkan Add to Cart Rate?\n",
    "analyze_binary_metric_strict(df1, 'added_to_cart', alpha=0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b68c56cd",
   "metadata": {},
   "source": [
    "### Smart analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "cf5172fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def execute_smart_analysis(df, alpha=0.05):\n",
    "    \"\"\"\n",
    "    Fungsi 'Palugada':\n",
    "    1. Deteksi jenis metrik otomatis.\n",
    "    2. Deteksi Control Variant otomatis.\n",
    "    3. LANGSUNG EKSEKUSI analisis statistik yang sesuai.\n",
    "    \"\"\"\n",
    "    \n",
    "    # --- 1. SETUP AWAL ---\n",
    "    try:\n",
    "        variant_col_index = df.columns.get_loc('variant')\n",
    "        metric_columns = df.columns[variant_col_index + 1:]\n",
    "        \n",
    "        # Deteksi Control (Urutan Abjad Pertama)\n",
    "        unique_variants = sorted(df['variant'].unique())\n",
    "        control_variant = unique_variants[0]\n",
    "        num_variants = len(unique_variants)\n",
    "        \n",
    "        print(f\"\\n{'#'*80}\")\n",
    "        print(f\"ðŸš€ AUTO-EXECUTING ANALYSIS\")\n",
    "        print(f\"â„¹ï¸  Variants: {num_variants} -> {unique_variants}\")\n",
    "        print(f\"â„¹ï¸  Control Group: '{control_variant}'\")\n",
    "        print(f\"â„¹ï¸  Alpha: {alpha}\")\n",
    "        print(f\"{'#'*80}\\n\")\n",
    "        \n",
    "    except KeyError:\n",
    "        print(\"âŒ Error: Kolom 'variant' tidak ditemukan.\")\n",
    "        return\n",
    "\n",
    "    # --- 2. LOOPING SEMUA METRIK ---\n",
    "    for metric in metric_columns:\n",
    "        clean_data = df[metric].dropna()\n",
    "        unique_values = clean_data.unique()\n",
    "        dtype = clean_data.dtype\n",
    "        \n",
    "        # --- 3. KLASIFIKASI & EKSEKUSI ---\n",
    "        \n",
    "        # A. CATEGORICAL (Skip / Warning)\n",
    "        if dtype == 'object' or dtype.name == 'category':\n",
    "            print(f\"âš ï¸  SKIPPING '{metric}': Tipe data Categorical/String belum didukung otomatis.\")\n",
    "            print(\"-\" * 50)\n",
    "            continue # Lanjut ke metrik berikutnya\n",
    "            \n",
    "        # B. BINARY (0/1) -> Panggil analyze_binary_metric_strict\n",
    "        elif set(unique_values).issubset({0, 1, 0.0, 1.0}):\n",
    "            analyze_binary_metric_strict(\n",
    "                df, metric, \n",
    "                control_variant=control_variant, \n",
    "                alpha=alpha\n",
    "            )\n",
    "            \n",
    "        # C. COUNT (Keywords) -> Panggil analyze_count_metric_strict\n",
    "        elif any(keyword in metric for keyword in ['pages', 'products', 'items', 'clicks', 'interactions', 'slider']):\n",
    "            analyze_count_metric_strict(\n",
    "                df, metric, \n",
    "                control_variant=control_variant, \n",
    "                alpha=alpha\n",
    "            )\n",
    "            \n",
    "        # D. CONTINUOUS (Keywords) -> Panggil analyze_continuous_metric_strict\n",
    "        elif any(keyword in metric for keyword in ['revenue', 'price', 'money', 'sales', 'time', 'duration']):\n",
    "            analyze_continuous_metric_strict(\n",
    "                df, metric, \n",
    "                control_variant=control_variant, \n",
    "                alpha=alpha\n",
    "            )\n",
    "\n",
    "        # E. COUNT (Integer Fallback) -> Panggil analyze_count_metric_strict\n",
    "        elif np.all(clean_data % 1 == 0):\n",
    "            analyze_count_metric_strict(\n",
    "                df, metric, \n",
    "                control_variant=control_variant, \n",
    "                alpha=alpha\n",
    "            )\n",
    "                \n",
    "        # F. CONTINUOUS (Real Fallback) -> Panggil analyze_continuous_metric_strict\n",
    "        else:\n",
    "            analyze_continuous_metric_strict(\n",
    "                df, metric, \n",
    "                control_variant=control_variant, \n",
    "                alpha=alpha\n",
    "            )\n",
    "            \n",
    "        # Kasih jarak biar enak bacanya\n",
    "        print(\"\\n\" + \"...\"*30 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "4d8e70a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "################################################################################\n",
      "ðŸš€ AUTO-EXECUTING ANALYSIS\n",
      "â„¹ï¸  Variants: 3 -> ['A_selected_by_others_only', 'B_similar_products_top', 'C_selected_by_others_top']\n",
      "â„¹ï¸  Control Group: 'A_selected_by_others_only'\n",
      "â„¹ï¸  Alpha: 0.05\n",
      "################################################################################\n",
      "\n",
      "\n",
      "================================================================================\n",
      "âš–ï¸  STRICT BINARY ANALYSIS: add_to_cart_rate\n",
      "================================================================================\n",
      "â„¹ï¸  Info: Found 3 Variants\n",
      "â„¹ï¸  Control Group: 'A_selected_by_others_only'\n",
      "â„¹ï¸  Settings: Alpha = 0.05\n",
      "\n",
      "[STEP 1] Metric Type: Binary Data (0/1)\n",
      "\n",
      "[STEP 2] Checking Assumptions (Sample Size)\n",
      "   -> Status: Sample size is sufficient.\n",
      "\n",
      "[STEP 3] Executing Test...\n",
      "   -> Selected Test: Chi-Square Test of Independence\n",
      "   -> P-Value: 0.98885\n",
      "\n",
      "   [POST-HOC ANALYSIS]\n",
      "   -> Skipped because Global Test was NOT significant.\n",
      "\n",
      "[CONCLUSION] Threshold: 0.05\n",
      "âŒ NOT SIGNIFICANT. (Chi-Square Test of Independence failed to reject H0).\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "..........................................................................................\n",
      "\n",
      "\n",
      "================================================================================\n",
      "ðŸ“Š STRICT COUNT ANALYSIS: slider_interactions\n",
      "================================================================================\n",
      "â„¹ï¸  Info: Found 3 Variants\n",
      "â„¹ï¸  Control Group: 'A_selected_by_others_only'\n",
      "â„¹ï¸  Settings: Alpha Threshold = 0.05\n",
      "\n",
      "[STEP 1] Metric Type: Count Data (Integer)\n",
      "\n",
      "[STEP 2] Checking Distribution (Dispersion Check)\n",
      "   -> Mean: 2.2152 | Variance: 2.1532\n",
      "   -> Ratio: 0.97x\n",
      "   -> Diagnosis: Poisson / Underdispersed\n",
      "   -> Decision:  Data is stable (Poisson). Using Poisson Rate Test.\n",
      "\n",
      "[STEP 3] Executing Test...\n",
      "   -> Selected Test: Kruskal-Wallis H Test\n",
      "   -> P-Value: 0.16215\n",
      "\n",
      "   [POST-HOC ANALYSIS]\n",
      "   -> Skipped because Global Test was NOT significant.\n",
      "\n",
      "[CONCLUSION] Threshold: 0.05\n",
      "âŒ NOT SIGNIFICANT. (Kruskal-Wallis H Test failed to reject H0).\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "..........................................................................................\n",
      "\n",
      "\n",
      "================================================================================\n",
      "ðŸ’° STRICT CONTINUOUS ANALYSIS: revenue_from_recommendations\n",
      "================================================================================\n",
      "â„¹ï¸  Info: Found 3 Variants\n",
      "â„¹ï¸  Control Group: 'A_selected_by_others_only'\n",
      "â„¹ï¸  Settings: Alpha = 0.05\n",
      "\n",
      "[STEP 1] Metric Type: Continuous Data (Real Numbers)\n",
      "\n",
      "[STEP 2] Checking Distribution (Shapiro-Wilk Test)\n",
      "   -> A_selected_by_others_only: p=0.00000 -> âŒ Skewed\n",
      "   -> B_similar_products_top: p=0.00000 -> âŒ Skewed\n",
      "   -> C_selected_by_others_top: p=0.00000 -> âŒ Skewed\n",
      "   -> Final Diagnosis: Skewed / Non-Normal Distribution\n",
      "   -> Decision: Data is Skewed. MUST use Non-Parametric Test.\n",
      "\n",
      "[STEP 3] Executing Test...\n",
      "   -> Selected Test: Kruskal-Wallis H Test\n",
      "   -> P-Value: 0.00000\n",
      "\n",
      "   [POST-HOC ANALYSIS - ALPHA 0.05]\n",
      "      â€¢ A_selected_by_others_only vs B_similar_products_top (Mann-Whitney)\n",
      "        -> Diff: 0.9027 | p=0.00000 -> âœ… DIFF\n",
      "      â€¢ A_selected_by_others_only vs C_selected_by_others_top (Mann-Whitney)\n",
      "        -> Diff: 0.2151 | p=0.00007 -> âœ… DIFF\n",
      "      â€¢ B_similar_products_top vs C_selected_by_others_top (Mann-Whitney)\n",
      "        -> Diff: -0.6876 | p=0.00000 -> âœ… DIFF\n",
      "\n",
      "[CONCLUSION] Threshold: 0.05\n",
      "âœ… SIGNIFICANT. (Kruskal-Wallis H Test rejected H0).\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "..........................................................................................\n",
      "\n",
      "\n",
      "================================================================================\n",
      "ðŸ“Š STRICT COUNT ANALYSIS: products_per_order\n",
      "================================================================================\n",
      "â„¹ï¸  Info: Found 3 Variants\n",
      "â„¹ï¸  Control Group: 'A_selected_by_others_only'\n",
      "â„¹ï¸  Settings: Alpha Threshold = 0.05\n",
      "\n",
      "[STEP 1] Metric Type: Count Data (Integer)\n",
      "\n",
      "[STEP 2] Checking Distribution (Dispersion Check)\n",
      "   -> Mean: 3.1563 | Variance: 0.7916\n",
      "   -> Ratio: 0.25x\n",
      "   -> Diagnosis: Poisson / Underdispersed\n",
      "   -> Decision:  Data is stable (Poisson). Using Poisson Rate Test.\n",
      "\n",
      "[STEP 3] Executing Test...\n",
      "   -> Selected Test: Kruskal-Wallis H Test\n",
      "   -> P-Value: 0.00000\n",
      "\n",
      "   [POST-HOC ANALYSIS - ALPHA 0.05]\n",
      "   -> Checking pairwise differences...\n",
      "      â€¢ A_selected_by_others_only vs B_similar_products_top\n",
      "        -> Diff: -0.1112 | p=0.00000 -> âœ… DIFF\n",
      "      â€¢ A_selected_by_others_only vs C_selected_by_others_top\n",
      "        -> Diff: -0.0576 | p=0.00047 -> âœ… DIFF\n",
      "      â€¢ B_similar_products_top vs C_selected_by_others_top\n",
      "        -> Diff: 0.0536 | p=0.00252 -> âœ… DIFF\n",
      "\n",
      "[CONCLUSION] Threshold: 0.05\n",
      "âœ… SIGNIFICANT. (Kruskal-Wallis H Test rejected H0).\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "..........................................................................................\n",
      "\n",
      "\n",
      "================================================================================\n",
      "ðŸ’° STRICT CONTINUOUS ANALYSIS: avg_product_price\n",
      "================================================================================\n",
      "â„¹ï¸  Info: Found 3 Variants\n",
      "â„¹ï¸  Control Group: 'A_selected_by_others_only'\n",
      "â„¹ï¸  Settings: Alpha = 0.05\n",
      "\n",
      "[STEP 1] Metric Type: Continuous Data (Real Numbers)\n",
      "\n",
      "[STEP 2] Checking Distribution (Shapiro-Wilk Test)\n",
      "   -> A_selected_by_others_only: p=0.00000 -> âŒ Skewed\n",
      "   -> B_similar_products_top: p=0.00000 -> âŒ Skewed\n",
      "   -> C_selected_by_others_top: p=0.00000 -> âŒ Skewed\n",
      "   -> Final Diagnosis: Skewed / Non-Normal Distribution\n",
      "   -> Decision: Data is Skewed. MUST use Non-Parametric Test.\n",
      "\n",
      "[STEP 3] Executing Test...\n",
      "   -> Selected Test: Kruskal-Wallis H Test\n",
      "   -> P-Value: 0.00000\n",
      "\n",
      "   [POST-HOC ANALYSIS - ALPHA 0.05]\n",
      "      â€¢ A_selected_by_others_only vs B_similar_products_top (Mann-Whitney)\n",
      "        -> Diff: 0.4043 | p=0.00000 -> âœ… DIFF\n",
      "      â€¢ A_selected_by_others_only vs C_selected_by_others_top (Mann-Whitney)\n",
      "        -> Diff: 0.2558 | p=0.00000 -> âœ… DIFF\n",
      "      â€¢ B_similar_products_top vs C_selected_by_others_top (Mann-Whitney)\n",
      "        -> Diff: -0.1485 | p=0.00000 -> âœ… DIFF\n",
      "\n",
      "[CONCLUSION] Threshold: 0.05\n",
      "âœ… SIGNIFICANT. (Kruskal-Wallis H Test rejected H0).\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "..........................................................................................\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pijar2000\\AppData\\Local\\Temp\\ipykernel_21736\\2121774899.py:59: UserWarning: scipy.stats.shapiro: For N > 5000, computed p-value may not be accurate. Current N is 6000.\n",
      "  stat, p_shapiro = stats.shapiro(data)\n"
     ]
    }
   ],
   "source": [
    "# Analisis SEMUA kolom di df1 sekaligus\n",
    "execute_smart_analysis(df3, alpha=0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae3c48ed",
   "metadata": {},
   "source": [
    "### Table Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "74502ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text_summary(df, variant_col='variant', control_variant=None, alpha=0.05):\n",
    "    \"\"\"\n",
    "    Menghasilkan SUMMARY TABLE berbasis TEKS (Console Friendly).\n",
    "    Fixed: Menggunakan Jarque-Bera jika N > 5000 untuk menghindari warning Shapiro.\n",
    "    \"\"\"\n",
    "    \n",
    "    # --- 1. SETUP & DETEKSI VARIANT ---\n",
    "    try:\n",
    "        var_col_idx = df.columns.get_loc(variant_col)\n",
    "        metric_cols = df.columns[var_col_idx + 1:]\n",
    "    except KeyError:\n",
    "        print(\"âŒ Error: Kolom variant tidak ditemukan.\")\n",
    "        return\n",
    "\n",
    "    unique_variants = sorted(df[variant_col].unique())\n",
    "    num_variants = len(unique_variants)\n",
    "    \n",
    "    # Tentukan Control (Default: Abjad Pertama)\n",
    "    if control_variant is None:\n",
    "        control_variant = unique_variants[0]\n",
    "    elif control_variant not in unique_variants:\n",
    "        print(f\"âŒ Error: Control '{control_variant}' tidak ada di data.\")\n",
    "        return\n",
    "\n",
    "    # --- 2. HEADER TABEL ---\n",
    "    print(\"\\n\" + \"=\"*105)\n",
    "    print(f\"ðŸ“Š EXPERIMENT SUMMARY REPORT\")\n",
    "    print(f\"   â€¢ Variants: {num_variants} ({', '.join(unique_variants)})\")\n",
    "    print(f\"   â€¢ Control : {control_variant}\")\n",
    "    print(f\"   â€¢ Alpha   : {alpha}\")\n",
    "    print(\"=\"*105)\n",
    "    \n",
    "    header = f\"| {'METRIC NAME':<25} | {'TYPE':<12} | {'TEST USED':<25} | {'LIFT (%)':<10} | {'P-VALUE':<10} | {'SIG?':<5} |\"\n",
    "    print(header)\n",
    "    print(\"|\" + \"-\"*27 + \"|\" + \"-\"*14 + \"|\" + \"-\"*27 + \"|\" + \"-\"*12 + \"|\" + \"-\"*12 + \"|\" + \"-\"*7 + \"|\")\n",
    "\n",
    "    # --- 3. LOOPING METRIK & ANALISIS ---\n",
    "    for metric in metric_cols:\n",
    "        # Data Cleaning\n",
    "        clean_data = df[[variant_col, metric]].dropna()\n",
    "        groups = [clean_data[clean_data[variant_col] == v][metric] for v in unique_variants]\n",
    "        \n",
    "        # Ambil data Control untuk Baseline\n",
    "        ctrl_data = clean_data[clean_data[variant_col] == control_variant][metric]\n",
    "        \n",
    "        # Variabel Default\n",
    "        metric_type = \"Unknown\"\n",
    "        test_name = \"Unknown\"\n",
    "        p_val = 1.0\n",
    "        lift = 0.0\n",
    "        \n",
    "        unique_vals = clean_data[metric].unique()\n",
    "        \n",
    "        # === LOGIKA ANALISIS (SMART MODE) ===\n",
    "        \n",
    "        # A. BINARY\n",
    "        if set(unique_vals).issubset({0, 1, 0.0, 1.0}):\n",
    "            metric_type = \"Binary\"\n",
    "            successes = [g.sum() for g in groups]\n",
    "            nobs = [g.count() for g in groups]\n",
    "            \n",
    "            if num_variants == 2:\n",
    "                test_name = \"Z-Test (Prop)\"\n",
    "                stat, p_val = proportions_ztest(successes, nobs)\n",
    "            else:\n",
    "                test_name = \"Chi-Square\"\n",
    "                obs = [[s, n-s] for s, n in zip(successes, nobs)]\n",
    "                stat, p_val, _, _ = stats.chi2_contingency(obs)\n",
    "\n",
    "        # B. COUNT & CONTINUOUS\n",
    "        else:\n",
    "            is_count = np.all(clean_data[metric] % 1 == 0) and (clean_data[metric].min() >= 0)\n",
    "            \n",
    "            if is_count:\n",
    "                metric_type = \"Count\"\n",
    "                mean_v = ctrl_data.mean()\n",
    "                var_v = ctrl_data.var()\n",
    "                ratio = var_v / mean_v if mean_v > 0 else 0\n",
    "                \n",
    "                if ratio <= 1.5:\n",
    "                    test_mode = \"Stable\"\n",
    "                else:\n",
    "                    test_mode = \"Skewed\"\n",
    "            else:\n",
    "                metric_type = \"Continuous\"\n",
    "                \n",
    "                # --- PERBAIKAN DI SINI: LOGIKA NORMALITY ---\n",
    "                # Jika N > 5000, Shapiro Warning -> Ganti pakai Jarque-Bera\n",
    "                if len(ctrl_data) > 5000:\n",
    "                    stat_jb, p_jb = stats.jarque_bera(ctrl_data)\n",
    "                    test_mode = \"Normal\" if p_jb > 0.05 else \"Skewed\"\n",
    "                elif len(ctrl_data) >= 3:\n",
    "                    stat_sh, p_shapiro = stats.shapiro(ctrl_data)\n",
    "                    test_mode = \"Normal\" if p_shapiro > 0.05 else \"Skewed\"\n",
    "                else:\n",
    "                    test_mode = \"SmallSample\"\n",
    "\n",
    "            # Pilih Test Berdasarkan Mode\n",
    "            if num_variants == 2:\n",
    "                if test_mode in [\"Stable\", \"Normal\"]:\n",
    "                    test_name = \"T-Test (Welch)\" if metric_type == \"Continuous\" else \"Poisson Test\"\n",
    "                    _, p_val = stats.ttest_ind(groups[0], groups[1], equal_var=False)\n",
    "                else:\n",
    "                    test_name = \"Mann-Whitney U\"\n",
    "                    _, p_val = stats.mannwhitneyu(groups[0], groups[1], alternative='two-sided')\n",
    "            else:\n",
    "                if test_mode in [\"Stable\", \"Normal\"]:\n",
    "                    test_name = \"ANOVA (One-Way)\"\n",
    "                    _, p_val = stats.f_oneway(*groups)\n",
    "                else:\n",
    "                    test_name = \"Kruskal-Wallis\"\n",
    "                    _, p_val = stats.kruskal(*groups)\n",
    "\n",
    "        # === HITUNG LIFT ===\n",
    "        mean_ctrl = ctrl_data.mean()\n",
    "        \n",
    "        other_means = []\n",
    "        for v in unique_variants:\n",
    "            if v != control_variant:\n",
    "                mean_trt = clean_data[clean_data[variant_col] == v][metric].mean()\n",
    "                other_means.append(mean_trt)\n",
    "        \n",
    "        best_trt_mean = max(other_means) if other_means else 0\n",
    "        \n",
    "        if mean_ctrl == 0:\n",
    "            lift_str = \"N/A\"\n",
    "        else:\n",
    "            lift_val = (best_trt_mean - mean_ctrl) / mean_ctrl * 100\n",
    "            lift_str = f\"{lift_val:+.2f}%\"\n",
    "\n",
    "        # === FINISHING TOUCH ===\n",
    "        sig_str = \"YES\" if p_val < alpha else \"NO\"\n",
    "        \n",
    "        row = f\"| {metric:<25} | {metric_type:<12} | {test_name:<25} | {lift_str:<10} | {p_val:<10.5f} | {sig_str:<5} |\"\n",
    "        print(row)\n",
    "\n",
    "    # --- 4. FOOTER ---\n",
    "    print(\"|\" + \"-\"*103 + \"|\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "85ded55b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================================================================================================\n",
      "ðŸ“Š EXPERIMENT SUMMARY REPORT\n",
      "   â€¢ Variants: 2 (A_horizontal_menu, B_dropdown_menu)\n",
      "   â€¢ Control : A_horizontal_menu\n",
      "   â€¢ Alpha   : 0.05\n",
      "=========================================================================================================\n",
      "| METRIC NAME               | TYPE         | TEST USED                 | LIFT (%)   | P-VALUE    | SIG?  |\n",
      "|---------------------------|--------------|---------------------------|------------|------------|-------|\n",
      "| pages_viewed              | Continuous   | Mann-Whitney U            | -2.01%     | 0.06748    | NO    |\n",
      "| added_to_cart             | Binary       | Z-Test (Prop)             | -10.34%    | 0.00000    | YES   |\n",
      "| bounced                   | Binary       | Z-Test (Prop)             | +2.63%     | 0.33544    | NO    |\n",
      "| revenue                   | Continuous   | Mann-Whitney U            | -10.51%    | 0.00000    | YES   |\n",
      "|-------------------------------------------------------------------------------------------------------|\n"
     ]
    }
   ],
   "source": [
    "# Contoh Pakai di df1\n",
    "generate_text_summary(df1, control_variant='A_horizontal_menu', alpha=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "5719ae5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from statsmodels.stats.proportion import proportions_ztest\n",
    "\n",
    "def generate_text_summary(df, variant_col='variant', control_variant=None, alpha=0.05):\n",
    "    \"\"\"\n",
    "    Menghasilkan SUMMARY TABLE berbasis TEKS (Console Friendly).\n",
    "    PLUS: Mengembalikan dictionary berisi hasil analisis (P-Value, Lift, dll).\n",
    "    \"\"\"\n",
    "    \n",
    "    # --- 1. SETUP & DETEKSI VARIANT ---\n",
    "    try:\n",
    "        var_col_idx = df.columns.get_loc(variant_col)\n",
    "        metric_cols = df.columns[var_col_idx + 1:]\n",
    "    except KeyError:\n",
    "        print(\"âŒ Error: Kolom variant tidak ditemukan.\")\n",
    "        return {} # Return kosong biar gak error\n",
    "\n",
    "    unique_variants = sorted(df[variant_col].unique())\n",
    "    num_variants = len(unique_variants)\n",
    "    \n",
    "    if control_variant is None:\n",
    "        control_variant = unique_variants[0]\n",
    "    elif control_variant not in unique_variants:\n",
    "        print(f\"âŒ Error: Control '{control_variant}' tidak ada di data.\")\n",
    "        return {}\n",
    "\n",
    "    # --- 2. HEADER TABEL ---\n",
    "    print(\"\\n\" + \"=\"*105)\n",
    "    print(f\"ðŸ“Š EXPERIMENT SUMMARY REPORT\")\n",
    "    print(f\"   â€¢ Variants: {num_variants} ({', '.join(unique_variants)})\")\n",
    "    print(f\"   â€¢ Control : {control_variant}\")\n",
    "    print(f\"   â€¢ Alpha   : {alpha}\")\n",
    "    print(\"=\"*105)\n",
    "    \n",
    "    header = f\"| {'METRIC NAME':<25} | {'TYPE':<12} | {'TEST USED':<25} | {'LIFT (%)':<10} | {'P-VALUE':<10} | {'SIG?':<5} |\"\n",
    "    print(header)\n",
    "    print(\"|\" + \"-\"*27 + \"|\" + \"-\"*14 + \"|\" + \"-\"*27 + \"|\" + \"-\"*12 + \"|\" + \"-\"*12 + \"|\" + \"-\"*7 + \"|\")\n",
    "\n",
    "    # Dictionary untuk menyimpan hasil\n",
    "    # Format Key nanti: \"nama_metric\" -> {p_value: ..., lift: ...}\n",
    "    stored_results = {}\n",
    "\n",
    "    # --- 3. LOOPING METRIK & ANALISIS ---\n",
    "    for metric in metric_cols:\n",
    "        clean_data = df[[variant_col, metric]].dropna()\n",
    "        groups = [clean_data[clean_data[variant_col] == v][metric] for v in unique_variants]\n",
    "        ctrl_data = clean_data[clean_data[variant_col] == control_variant][metric]\n",
    "        unique_vals = clean_data[metric].unique()\n",
    "        \n",
    "        # Variabel Default\n",
    "        metric_type = \"Unknown\"\n",
    "        test_name = \"Unknown\"\n",
    "        p_val = 1.0\n",
    "        \n",
    "        # A. BINARY\n",
    "        if set(unique_vals).issubset({0, 1, 0.0, 1.0}):\n",
    "            metric_type = \"Binary\"\n",
    "            successes = [g.sum() for g in groups]\n",
    "            nobs = [g.count() for g in groups]\n",
    "            \n",
    "            if num_variants == 2:\n",
    "                test_name = \"Z-Test (Prop)\"\n",
    "                _, p_val = proportions_ztest(successes, nobs)\n",
    "            else:\n",
    "                test_name = \"Chi-Square\"\n",
    "                obs = [[s, n-s] for s, n in zip(successes, nobs)]\n",
    "                _, p_val, _, _ = stats.chi2_contingency(obs)\n",
    "\n",
    "        # B. COUNT & CONTINUOUS\n",
    "        else:\n",
    "            is_count = np.all(clean_data[metric] % 1 == 0) and (clean_data[metric].min() >= 0)\n",
    "            \n",
    "            if is_count:\n",
    "                metric_type = \"Count\"\n",
    "                mean_v = ctrl_data.mean()\n",
    "                var_v = ctrl_data.var()\n",
    "                ratio = var_v / mean_v if mean_v > 0 else 0\n",
    "                test_mode = \"Stable\" if ratio <= 1.5 else \"Skewed\"\n",
    "            else:\n",
    "                metric_type = \"Continuous\"\n",
    "                # Logika Jarque-Bera\n",
    "                if len(ctrl_data) > 5000:\n",
    "                    stat_jb, p_jb = stats.jarque_bera(ctrl_data)\n",
    "                    test_mode = \"Normal\" if p_jb > 0.05 else \"Skewed\"\n",
    "                elif len(ctrl_data) >= 3:\n",
    "                    stat_sh, p_shapiro = stats.shapiro(ctrl_data)\n",
    "                    test_mode = \"Normal\" if p_shapiro > 0.05 else \"Skewed\"\n",
    "                else:\n",
    "                    test_mode = \"SmallSample\"\n",
    "\n",
    "            # Pilih Test\n",
    "            if num_variants == 2:\n",
    "                if test_mode in [\"Stable\", \"Normal\"]:\n",
    "                    test_name = \"T-Test (Welch)\" if metric_type == \"Continuous\" else \"Poisson Test\"\n",
    "                    _, p_val = stats.ttest_ind(groups[0], groups[1], equal_var=False)\n",
    "                else:\n",
    "                    test_name = \"Mann-Whitney U\"\n",
    "                    _, p_val = stats.mannwhitneyu(groups[0], groups[1], alternative='two-sided')\n",
    "            else:\n",
    "                if test_mode in [\"Stable\", \"Normal\"]:\n",
    "                    test_name = \"ANOVA\"\n",
    "                    _, p_val = stats.f_oneway(*groups)\n",
    "                else:\n",
    "                    test_name = \"Kruskal-Wallis\"\n",
    "                    _, p_val = stats.kruskal(*groups)\n",
    "\n",
    "        # Hitung Lift\n",
    "        mean_ctrl = ctrl_data.mean()\n",
    "        other_means = [clean_data[clean_data[variant_col] == v][metric].mean() for v in unique_variants if v != control_variant]\n",
    "        best_trt_mean = max(other_means) if other_means else 0\n",
    "        \n",
    "        lift_val = 0.0\n",
    "        lift_str = \"N/A\"\n",
    "        \n",
    "        if mean_ctrl != 0:\n",
    "            lift_val = (best_trt_mean - mean_ctrl) / mean_ctrl # Float (0.15)\n",
    "            lift_str = f\"{lift_val*100:+.2f}%\"\n",
    "\n",
    "        # Simpan ke Dictionary\n",
    "        stored_results[metric] = {\n",
    "            \"p_value\": p_val,\n",
    "            \"lift\": lift_val,\n",
    "            \"significant\": p_val < alpha\n",
    "        }\n",
    "\n",
    "        # Print Row\n",
    "        sig_str = \"YES\" if p_val < alpha else \"NO\"\n",
    "        row = f\"| {metric:<25} | {metric_type:<12} | {test_name:<25} | {lift_str:<10} | {p_val:<10.5f} | {sig_str:<5} |\"\n",
    "        print(row)\n",
    "\n",
    "    # --- 4. FOOTER ---\n",
    "    print(\"|\" + \"-\"*103 + \"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ecfa51b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
