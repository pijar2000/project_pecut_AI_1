{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "586a7584",
   "metadata": {},
   "source": [
    "# Statistical Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f930927",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7c68cad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "COMPREHENSIVE VALIDATION SUITE\n",
      "Validating All 5 A/B Tests\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "TEST: Test 1: Menu Design\n",
      "================================================================================\n",
      "Loaded: 7,000 rows\n",
      "Variants (2):\n",
      "   - A_horizontal_menu: 3,500 (50.0%)\n",
      "   - B_dropdown_menu: 3,500 (50.0%)\n",
      "\n",
      "Validation Results:\n",
      "  SRM Test:        PASS (p=1.0000)\n",
      "  Balance:         OK (SMD=0.026)\n",
      "  Temporal:        OK (CV=0.057)\n",
      "\n",
      "================================================================================\n",
      "TEST: Test 2: Novelty Slider\n",
      "================================================================================\n",
      "Loaded: 16,000 rows\n",
      "Variants (2):\n",
      "   - A_manual_novelties: 8,000 (50.0%)\n",
      "   - B_personalized_novelties: 8,000 (50.0%)\n",
      "\n",
      "Validation Results:\n",
      "  SRM Test:        PASS (p=1.0000)\n",
      "  Balance:         OK (SMD=0.028)\n",
      "  Temporal:        OK (CV=0.038)\n",
      "\n",
      "================================================================================\n",
      "TEST: Test 3: Product Sliders\n",
      "================================================================================\n",
      "Loaded: 18,000 rows\n",
      "Variants (3):\n",
      "   - A_selected_by_others_only: 6,000 (33.3%)\n",
      "   - B_similar_products_top: 6,000 (33.3%)\n",
      "   - C_selected_by_others_top: 6,000 (33.3%)\n",
      "\n",
      "Validation Results:\n",
      "  SRM Test:        PASS (p=1.0000)\n",
      "  Balance:         OK (SMD=0.039)\n",
      "  Temporal:        OK (CV=0.049)\n",
      "\n",
      "================================================================================\n",
      "TEST: Test 4: Customer Reviews\n",
      "================================================================================\n",
      "Loaded: 42,000 rows\n",
      "Variants (2):\n",
      "   - A_no_featured_reviews: 21,000 (50.0%)\n",
      "   - B_featured_reviews: 21,000 (50.0%)\n",
      "\n",
      "Validation Results:\n",
      "  SRM Test:        PASS (p=1.0000)\n",
      "  Balance:         OK (SMD=0.014)\n",
      "  Temporal:        OK (CV=0.047)\n",
      "\n",
      "================================================================================\n",
      "TEST: Test 5: Search Engine\n",
      "================================================================================\n",
      "Loaded: 19,000 rows\n",
      "Variants (2):\n",
      "   - A_hybris_search: 9,500 (50.0%)\n",
      "   - B_algolia_search: 9,500 (50.0%)\n",
      "\n",
      "Validation Results:\n",
      "  SRM Test:        PASS (p=1.0000)\n",
      "  Balance:         OK (SMD=0.032)\n",
      "  Temporal:        OK (CV=0.026)\n",
      "\n",
      "\n",
      "================================================================================\n",
      "SUMMARY TABLE\n",
      "================================================================================\n",
      "\n",
      "Test                                  N      SRM    Balance   Temporal    Valid\n",
      "--------------------------------------------------------------------------------\n",
      "Test 1: Menu Design               7,000     PASS       Good     Stable      YES\n",
      "Test 2: Novelty Slider           16,000     PASS       Good     Stable      YES\n",
      "Test 3: Product Sliders          18,000     PASS       Good     Stable      YES\n",
      "Test 4: Customer Reviews         42,000     PASS       Good     Stable      YES\n",
      "Test 5: Search Engine            19,000     PASS       Good     Stable      YES\n",
      "\n",
      "================================================================================\n",
      "OVERALL STATISTICS\n",
      "================================================================================\n",
      "\n",
      "Total samples across all tests: 102,000\n",
      "Tests passed SRM check: 5/5\n",
      "Tests fully valid: 5/5\n",
      "\n",
      " ALL TESTS ARE VALID\n",
      "\n",
      "All experiments passed validation checks!\n",
      "You can proceed with statistical analysis with full confidence.\n",
      "\n",
      "================================================================================\n",
      "RECOMMENDATIONS BY TEST\n",
      "================================================================================\n",
      "\n",
      "Test 1: Menu Design:\n",
      "All checks passed - proceed with analysis\n",
      "\n",
      "Test 2: Novelty Slider:\n",
      "All checks passed - proceed with analysis\n",
      "\n",
      "Test 3: Product Sliders:\n",
      "All checks passed - proceed with analysis\n",
      "\n",
      "Test 4: Customer Reviews:\n",
      "All checks passed - proceed with analysis\n",
      "\n",
      "Test 5: Search Engine:\n",
      "All checks passed - proceed with analysis\n",
      "\n",
      "================================================================================\n",
      "VALIDATION COMPLETE\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Complete Experimental Validation Framework for A/B Testing\n",
    "\n",
    "Implements ALL required validation checks:\n",
    "1. Sample Ratio Mismatch (SRM) Detection \n",
    "2. Covariate Balance Verification \n",
    "3. Temporal Stability Checks \n",
    "4. Multiple Testing Correction\n",
    "\n",
    "When run directly, validates all 5 A/B tests with comprehensive reporting.\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "from typing import Dict, List, Tuple, Optional, Union\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "\n",
    "class ExperimentValidator:\n",
    "    \"\"\"\n",
    "    Complete validation framework for A/B tests.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 srm_threshold: float = 0.001,\n",
    "                 balance_threshold: float = 0.2,\n",
    "                 temporal_threshold: float = 0.2):\n",
    "        self.srm_threshold = srm_threshold\n",
    "        self.balance_threshold = balance_threshold\n",
    "        self.temporal_threshold = temporal_threshold\n",
    "    \n",
    "    def sample_ratio_mismatch_test(self,\n",
    "                                   df: pd.DataFrame,\n",
    "                                   variant_col: str,\n",
    "                                   expected_ratio: Optional[Dict[str, float]] = None) -> Dict:\n",
    "        \"\"\"Sample Ratio Mismatch detection.\"\"\"\n",
    "        \n",
    "        observed = df[variant_col].value_counts().sort_index()\n",
    "        total = len(df)\n",
    "        n_variants = len(observed)\n",
    "        \n",
    "        if expected_ratio is None:\n",
    "            expected = pd.Series([total / n_variants] * n_variants, index=observed.index)\n",
    "        else:\n",
    "            expected = pd.Series({k: v * total for k, v in expected_ratio.items()})\n",
    "        \n",
    "        chi2_stat = np.sum((observed - expected)**2 / expected)\n",
    "        df_chi = n_variants - 1\n",
    "        pvalue = 1 - stats.chi2.cdf(chi2_stat, df_chi)\n",
    "        \n",
    "        has_srm = pvalue < self.srm_threshold\n",
    "        \n",
    "        result = {\n",
    "            'test': 'sample_ratio_mismatch',\n",
    "            'chi2_statistic': chi2_stat,\n",
    "            'degrees_of_freedom': df_chi,\n",
    "            'pvalue': pvalue,\n",
    "            'threshold': self.srm_threshold,\n",
    "            'has_srm': has_srm,\n",
    "            'observed_counts': observed.to_dict(),\n",
    "            'expected_counts': expected.to_dict(),\n",
    "            'observed_ratio': (observed / total).to_dict(),\n",
    "            'expected_ratio': (expected / total).to_dict()\n",
    "        }\n",
    "        \n",
    "        if has_srm:\n",
    "            result['warning'] = f\"CRITICAL: SRM detected (p={pvalue:.6f} < {self.srm_threshold}). Experiment is INVALID.\"\n",
    "        else:\n",
    "            result['message'] = f\"No SRM detected (p={pvalue:.4f}). Allocation is as expected.\"\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def covariate_balance_check(self,\n",
    "                                df: pd.DataFrame,\n",
    "                                variant_col: str,\n",
    "                                covariates: List[str],\n",
    "                                threshold: Optional[float] = None) -> Dict:\n",
    "        \"\"\"Covariate balance verification using SMD.\"\"\"\n",
    "        \n",
    "        if threshold is None:\n",
    "            threshold = self.balance_threshold\n",
    "        \n",
    "        variants = df[variant_col].unique()\n",
    "        \n",
    "        if len(variants) < 2:\n",
    "            return {'error': 'Need at least 2 variants for balance check'}\n",
    "        \n",
    "        balance_results = []\n",
    "        imbalanced_covariates = []\n",
    "        \n",
    "        for covariate in covariates:\n",
    "            if covariate not in df.columns:\n",
    "                warnings.warn(f\"Covariate '{covariate}' not found in dataframe\")\n",
    "                continue\n",
    "            \n",
    "            is_categorical = (\n",
    "                df[covariate].dtype == 'object' or \n",
    "                df[covariate].dtype.name == 'category' or\n",
    "                df[covariate].nunique() < 10\n",
    "            )\n",
    "            \n",
    "            if is_categorical:\n",
    "                for category in df[covariate].unique():\n",
    "                    proportions = {}\n",
    "                    for variant in variants:\n",
    "                        variant_data = df[df[variant_col] == variant][covariate]\n",
    "                        proportions[variant] = (variant_data == category).mean()\n",
    "                    \n",
    "                    variant_list = list(variants)\n",
    "                    p1 = proportions[variant_list[0]]\n",
    "                    p2 = proportions[variant_list[1]]\n",
    "                    p_pooled = (p1 + p2) / 2\n",
    "                    \n",
    "                    if p_pooled > 0 and p_pooled < 1:\n",
    "                        smd = abs(p1 - p2) / np.sqrt(p_pooled * (1 - p_pooled))\n",
    "                    else:\n",
    "                        smd = 0.0\n",
    "                    \n",
    "                    is_imbalanced = smd > threshold\n",
    "                    \n",
    "                    balance_results.append({\n",
    "                        'covariate': f\"{covariate}={category}\",\n",
    "                        'type': 'categorical',\n",
    "                        'variant_1': variant_list[0],\n",
    "                        'variant_2': variant_list[1],\n",
    "                        'proportion_1': p1,\n",
    "                        'proportion_2': p2,\n",
    "                        'smd': smd,\n",
    "                        'imbalanced': is_imbalanced\n",
    "                    })\n",
    "                    \n",
    "                    if is_imbalanced:\n",
    "                        imbalanced_covariates.append(f\"{covariate}={category}\")\n",
    "            else:\n",
    "                variant_stats = {}\n",
    "                for variant in variants:\n",
    "                    variant_data = df[df[variant_col] == variant][covariate]\n",
    "                    variant_stats[variant] = {\n",
    "                        'mean': variant_data.mean(),\n",
    "                        'std': variant_data.std(),\n",
    "                        'var': variant_data.var(),\n",
    "                        'n': len(variant_data)\n",
    "                    }\n",
    "                \n",
    "                variant_list = list(variants)\n",
    "                v1, v2 = variant_list[0], variant_list[1]\n",
    "                \n",
    "                mean_diff = abs(variant_stats[v1]['mean'] - variant_stats[v2]['mean'])\n",
    "                pooled_std = np.sqrt((variant_stats[v1]['var'] + variant_stats[v2]['var']) / 2)\n",
    "                \n",
    "                if pooled_std > 0:\n",
    "                    smd = mean_diff / pooled_std\n",
    "                else:\n",
    "                    smd = 0.0\n",
    "                \n",
    "                is_imbalanced = smd > threshold\n",
    "                \n",
    "                balance_results.append({\n",
    "                    'covariate': covariate,\n",
    "                    'type': 'continuous',\n",
    "                    'variant_1': variant_list[0],\n",
    "                    'variant_2': variant_list[1],\n",
    "                    'mean_1': variant_stats[v1]['mean'],\n",
    "                    'mean_2': variant_stats[v2]['mean'],\n",
    "                    'std_1': variant_stats[v1]['std'],\n",
    "                    'std_2': variant_stats[v2]['std'],\n",
    "                    'smd': smd,\n",
    "                    'imbalanced': is_imbalanced\n",
    "                })\n",
    "                \n",
    "                if is_imbalanced:\n",
    "                    imbalanced_covariates.append(covariate)\n",
    "        \n",
    "        balance_df = pd.DataFrame(balance_results)\n",
    "        max_smd = balance_df['smd'].max() if len(balance_df) > 0 else 0\n",
    "        n_imbalanced = len(imbalanced_covariates)\n",
    "        \n",
    "        if max_smd < 0.1:\n",
    "            message = f\"Excellent balance (max SMD={max_smd:.3f} < 0.1)\"\n",
    "        elif max_smd < threshold:\n",
    "            message = f\"Good balance (max SMD={max_smd:.3f} < {threshold})\"\n",
    "        else:\n",
    "            message = f\"{n_imbalanced} covariate(s) imbalanced (max SMD={max_smd:.3f} ≥ {threshold})\"\n",
    "        \n",
    "        return {\n",
    "            'test': 'covariate_balance',\n",
    "            'variants_compared': list(variants)[:2],\n",
    "            'balance_results': balance_df,\n",
    "            'imbalanced_covariates': imbalanced_covariates,\n",
    "            'n_imbalanced': n_imbalanced,\n",
    "            'max_smd': max_smd,\n",
    "            'threshold': threshold,\n",
    "            'message': message\n",
    "        }\n",
    "    \n",
    "    def temporal_stability_check(self,\n",
    "                                df: pd.DataFrame,\n",
    "                                variant_col: str,\n",
    "                                date_col: str,\n",
    "                                threshold: Optional[float] = None) -> Dict:\n",
    "        \"\"\"Temporal stability verification.\"\"\"\n",
    "        \n",
    "        if threshold is None:\n",
    "            threshold = self.temporal_threshold\n",
    "        \n",
    "        df = df.copy()\n",
    "        if not pd.api.types.is_datetime64_any_dtype(df[date_col]):\n",
    "            df[date_col] = pd.to_datetime(df[date_col])\n",
    "        \n",
    "        df['date'] = df[date_col].dt.date\n",
    "        daily_counts = df.groupby(['date', variant_col]).size().unstack(fill_value=0)\n",
    "        \n",
    "        cv_results = {}\n",
    "        for variant in daily_counts.columns:\n",
    "            counts = daily_counts[variant]\n",
    "            mean_count = counts.mean()\n",
    "            std_count = counts.std()\n",
    "            cv = std_count / mean_count if mean_count > 0 else 0.0\n",
    "            cv_results[variant] = cv\n",
    "        \n",
    "        max_cv = max(cv_results.values())\n",
    "        is_stable = max_cv < threshold\n",
    "        \n",
    "        message = (\n",
    "            f\"Stable allocation over time (max CV={max_cv:.3f} < {threshold})\" if is_stable\n",
    "            else f\"Unstable allocation (max CV={max_cv:.3f} ≥ {threshold})\"\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'test': 'temporal_stability',\n",
    "            'cv_by_variant': cv_results,\n",
    "            'max_cv': max_cv,\n",
    "            'threshold': threshold,\n",
    "            'is_stable': is_stable,\n",
    "            'daily_counts': daily_counts,\n",
    "            'n_days': len(daily_counts),\n",
    "            'message': message\n",
    "        }\n",
    "    \n",
    "    def multiple_testing_correction(self,\n",
    "                                    pvalues: List[float],\n",
    "                                    method: str = 'holm',\n",
    "                                    alpha: float = 0.05) -> Dict:\n",
    "        \"\"\"\n",
    "        Multiple testing correction.\n",
    "        \n",
    "        Methods:\n",
    "        - 'bonferroni': Most conservative (alpha/k)\n",
    "        - 'holm': Holm-Bonferroni (recommended for 5-10 tests)\n",
    "        - 'fdr_bh': Benjamini-Hochberg FDR (for >10 tests)\n",
    "        \n",
    "        References:\n",
    "        - Bonferroni (1936)\n",
    "        - Holm (1979)\n",
    "        - Benjamini & Hochberg (1995)\n",
    "        \"\"\"\n",
    "        \n",
    "        pvalues_array = np.array(pvalues)\n",
    "        n_tests = len(pvalues_array)\n",
    "        \n",
    "        # Apply correction\n",
    "        reject, pvals_corrected, alphacSidak, alphacBonf = multipletests(\n",
    "            pvalues_array,\n",
    "            alpha=alpha,\n",
    "            method=method\n",
    "        )\n",
    "        \n",
    "        method_names = {\n",
    "            'bonferroni': 'Bonferroni',\n",
    "            'holm': 'Holm-Bonferroni',\n",
    "            'fdr_bh': 'Benjamini-Hochberg FDR'\n",
    "        }\n",
    "        \n",
    "        return {\n",
    "            'test': 'multiple_testing_correction',\n",
    "            'method': method_names.get(method, method),\n",
    "            'n_tests': n_tests,\n",
    "            'alpha': alpha,\n",
    "            'original_pvalues': pvalues_array.tolist(),\n",
    "            'corrected_pvalues': pvals_corrected.tolist(),\n",
    "            'reject': reject.tolist(),\n",
    "            'n_significant_original': sum(pvalues_array < alpha),\n",
    "            'n_significant_corrected': sum(reject),\n",
    "            'message': (\n",
    "                f\"✓ Multiple testing correction applied: {method_names.get(method, method)}\\n\"\n",
    "                f\"  Original significant: {sum(pvalues_array < alpha)}/{n_tests}\\n\"\n",
    "                f\"  Corrected significant: {sum(reject)}/{n_tests}\"\n",
    "            )\n",
    "        }\n",
    "    \n",
    "    def run_all_validations(self,\n",
    "                           df: pd.DataFrame,\n",
    "                           variant_col: str,\n",
    "                           covariates: Optional[List[str]] = None,\n",
    "                           date_col: Optional[str] = None,\n",
    "                           metric_pvalues: Optional[List[float]] = None,\n",
    "                           correction_method: str = 'holm') -> Dict:\n",
    "        \"\"\"\n",
    "        Run complete validation suite including multiple testing correction.\n",
    "        \"\"\"\n",
    "        \n",
    "        results = {}\n",
    "        \n",
    "        print(\"=\" * 80)\n",
    "        print(\"EXPERIMENTAL VALIDATION SUITE\")\n",
    "        print(\"=\" * 80)\n",
    "        \n",
    "        # 1. SRM Test\n",
    "        print(\"\\n1. Sample Ratio Mismatch Test\")\n",
    "        print(\"-\" * 80)\n",
    "        srm_result = self.sample_ratio_mismatch_test(df, variant_col)\n",
    "        results['srm'] = srm_result\n",
    "        print(srm_result.get('message', srm_result.get('warning', '')))\n",
    "        \n",
    "        if srm_result['has_srm']:\n",
    "            print(\"\\n\" + \"=\" * 80)\n",
    "            print(\"VALIDATION FAILED: SRM detected.\")\n",
    "            print(\"=\" * 80)\n",
    "            return results\n",
    "        \n",
    "        # 2. Covariate Balance\n",
    "        if covariates:\n",
    "            print(\"\\n2. Covariate Balance Check\")\n",
    "            print(\"-\" * 80)\n",
    "            balance_result = self.covariate_balance_check(df, variant_col, covariates)\n",
    "            results['balance'] = balance_result\n",
    "            print(balance_result.get('message', ''))\n",
    "        \n",
    "        # 3. Temporal Stability\n",
    "        if date_col:\n",
    "            print(\"\\n3. Temporal Stability Check\")\n",
    "            print(\"-\" * 80)\n",
    "            temporal_result = self.temporal_stability_check(df, variant_col, date_col)\n",
    "            results['temporal'] = temporal_result\n",
    "            print(temporal_result.get('message', ''))\n",
    "        \n",
    "        # 4. Multiple Testing Correction\n",
    "        if metric_pvalues:\n",
    "            print(\"\\n4. Multiple Testing Correction\")\n",
    "            print(\"-\" * 80)\n",
    "            correction_result = self.multiple_testing_correction(\n",
    "                metric_pvalues,\n",
    "                method=correction_method,\n",
    "                alpha=0.05\n",
    "            )\n",
    "            results['multiple_testing'] = correction_result\n",
    "            print(correction_result.get('message', ''))\n",
    "        \n",
    "        # Summary\n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "        all_clear = (\n",
    "            not srm_result['has_srm'] and\n",
    "            (not covariates or balance_result.get('max_smd', 0) < self.balance_threshold) and\n",
    "            (not date_col or temporal_result.get('is_stable', True))\n",
    "        )\n",
    "        \n",
    "        if all_clear:\n",
    "            print(\"ALL VALIDATION CHECKS PASSED\")\n",
    "        else:\n",
    "            print(\"VALIDATION WARNINGS DETECTED\")\n",
    "        print(\"=\" * 80)\n",
    "        \n",
    "        return results\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# COMPREHENSIVE VALIDATION FOR ALL 5 A/B TESTS\n",
    "# ============================================================================\n",
    "\n",
    "def validate_test(test_name, csv_file, validator):\n",
    "    \"\"\"Validate a single test\"\"\"\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"TEST: {test_name}\")\n",
    "    print('='*80)\n",
    "    \n",
    "    try:\n",
    "        # Coba 1: Langsung di folder raw_dataset (Posisi standar)\n",
    "        if os.path.exists(f'raw_dataset/{csv_file}'):\n",
    "            df = pd.read_csv(f'raw_dataset/{csv_file}')\n",
    "            \n",
    "        # Coba 2: Mundur satu folder (Siapa tau kamu pindah folder)\n",
    "        elif os.path.exists(f'../raw_dataset/{csv_file}'):\n",
    "            df = pd.read_csv(f'../raw_dataset/{csv_file}')\n",
    "            \n",
    "        # Coba 3: Path Absolute (Jaga-jaga)\n",
    "        elif os.path.exists(f'/raw_dataset/{csv_file}'):\n",
    "            df = pd.read_csv(f'/raw_dataset/{csv_file}')\n",
    "            \n",
    "        else:\n",
    "            raise FileNotFoundError(f\"Cannot find {csv_file}\")\n",
    "            \n",
    "    except FileNotFoundError:\n",
    "        print(f\"File not found: {csv_file}\")\n",
    "        print(\"   Please run data_generation.py first!\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"Loaded: {len(df):,} rows\")\n",
    "    \n",
    "    # Variant split\n",
    "    variant_counts = df['variant'].value_counts()\n",
    "    print(f\"Variants ({len(variant_counts)}):\")\n",
    "    for variant, count in variant_counts.items():\n",
    "        pct = count / len(df) * 100\n",
    "        print(f\"   - {variant}: {count:,} ({pct:.1f}%)\")\n",
    "    \n",
    "    # Quick validation\n",
    "    srm = validator.sample_ratio_mismatch_test(df, 'variant')\n",
    "    balance = validator.covariate_balance_check(\n",
    "        df, 'variant', ['device_type', 'browser', 'region']\n",
    "    )\n",
    "    temporal = validator.temporal_stability_check(df, 'variant', 'timestamp')\n",
    "    \n",
    "    # Status\n",
    "    srm_status = \"PASS\" if not srm['has_srm'] else \"FAIL\"\n",
    "    balance_status = \"OK\" if balance['max_smd'] < 0.1 else \"WARNING\" if balance['max_smd'] < 0.2 else \"FAIL\"\n",
    "    temporal_status = \"OK\" if temporal['is_stable'] else \"WARNING\"\n",
    "    \n",
    "    print(f\"\\nValidation Results:\")\n",
    "    print(f\"  SRM Test:        {srm_status} (p={srm['pvalue']:.4f})\")\n",
    "    print(f\"  Balance:         {balance_status} (SMD={balance['max_smd']:.3f})\")\n",
    "    print(f\"  Temporal:        {temporal_status} (CV={temporal['max_cv']:.3f})\")\n",
    "    \n",
    "    return {\n",
    "        'test': test_name,\n",
    "        'n': len(df),\n",
    "        'n_variants': len(variant_counts),\n",
    "        'srm_pvalue': srm['pvalue'],\n",
    "        'srm_passed': not srm['has_srm'],\n",
    "        'balance_smd': balance['max_smd'],\n",
    "        'balance_ok': balance['max_smd'] < 0.2,\n",
    "        'temporal_cv': temporal['max_cv'],\n",
    "        'temporal_stable': temporal['is_stable'],\n",
    "        'overall_valid': not srm['has_srm'] and balance['max_smd'] < 0.2\n",
    "    }\n",
    "\n",
    "\n",
    "def validate_all_tests():\n",
    "    \"\"\"Run comprehensive validation on all 5 A/B tests\"\"\"\n",
    "    \n",
    "    print(\"=\"*80)\n",
    "    print(\"COMPREHENSIVE VALIDATION SUITE\")\n",
    "    print(\"Validating All 5 A/B Tests\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    validator = ExperimentValidator(\n",
    "        srm_threshold=0.001,\n",
    "        balance_threshold=0.2,\n",
    "        temporal_threshold=0.2\n",
    "    )\n",
    "    \n",
    "    tests = [\n",
    "        ('Test 1: Menu Design', 'test1_menu.csv'),\n",
    "        ('Test 2: Novelty Slider', 'test2_novelty_slider.csv'),\n",
    "        ('Test 3: Product Sliders', 'test3_product_sliders.csv'),\n",
    "        ('Test 4: Customer Reviews', 'test4_reviews.csv'),\n",
    "        ('Test 5: Search Engine', 'test5_search_engine.csv')\n",
    "    ]\n",
    "    \n",
    "    results = []\n",
    "    for test_name, csv_file in tests:\n",
    "        result = validate_test(test_name, csv_file, validator)\n",
    "        if result:\n",
    "            results.append(result)\n",
    "    \n",
    "    # Summary table\n",
    "    print(f\"\\n\\n{'='*80}\")\n",
    "    print(\"SUMMARY TABLE\")\n",
    "    print('='*80)\n",
    "    \n",
    "    if results:\n",
    "        summary_df = pd.DataFrame(results)\n",
    "        \n",
    "        print(f\"\\n{'Test':<30} {'N':>8} {'SRM':>8} {'Balance':>10} {'Temporal':>10} {'Valid':>8}\")\n",
    "        print('-'*80)\n",
    "        \n",
    "        for _, row in summary_df.iterrows():\n",
    "            test = row['test'][:28]\n",
    "            n = f\"{int(row['n']):,}\"\n",
    "            srm = \"PASS\" if row['srm_passed'] else \"FAIL\"\n",
    "            balance = \"Good\" if row['balance_ok'] else \"Warning\"\n",
    "            temporal = \"Stable\" if row['temporal_stable'] else \"Unstable\"\n",
    "            valid = \"YES\" if row['overall_valid'] else \"CHECK\"\n",
    "            \n",
    "            print(f\"{test:<30} {n:>8} {srm:>8} {balance:>10} {temporal:>10} {valid:>8}\")\n",
    "        \n",
    "        # Overall stats\n",
    "        print('\\n' + '='*80)\n",
    "        print(\"OVERALL STATISTICS\")\n",
    "        print('='*80)\n",
    "        \n",
    "        n_total = summary_df['n'].sum()\n",
    "        n_passed_srm = summary_df['srm_passed'].sum()\n",
    "        n_valid = summary_df['overall_valid'].sum()\n",
    "        \n",
    "        print(f\"\\nTotal samples across all tests: {n_total:,}\")\n",
    "        print(f\"Tests passed SRM check: {n_passed_srm}/{len(results)}\")\n",
    "        print(f\"Tests fully valid: {n_valid}/{len(results)}\")\n",
    "        \n",
    "        if n_passed_srm == len(results) and n_valid == len(results):\n",
    "            print(\"\\n ALL TESTS ARE VALID\")\n",
    "            print(\"\\nAll experiments passed validation checks!\")\n",
    "            print(\"You can proceed with statistical analysis with full confidence.\")\n",
    "        elif n_passed_srm < len(results):\n",
    "            print(\"\\n CRITICAL ISSUES DETECTED\")\n",
    "            print(\"\\nSome tests failed SRM check - DO NOT analyze those tests!\")\n",
    "        else:\n",
    "            print(\"\\nMINOR WARNINGS DETECTED\")\n",
    "            print(\"\\nTests passed critical checks but have minor balance/temporal issues.\")\n",
    "            print(\"Proceed with caution and consider causal adjustment methods.\")\n",
    "        \n",
    "        # Detailed recommendations\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"RECOMMENDATIONS BY TEST\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        for _, row in summary_df.iterrows():\n",
    "            print(f\"\\n{row['test']}:\")\n",
    "            if row['overall_valid']:\n",
    "                print(\"All checks passed - proceed with analysis\")\n",
    "            else:\n",
    "                if not row['srm_passed']:\n",
    "                    print(\"    SRM FAILED - DO NOT ANALYZE\")\n",
    "                    print(\"     → Investigate randomization bug\")\n",
    "                    print(\"     → Restart experiment after fix\")\n",
    "                elif not row['balance_ok']:\n",
    "                    print(\"    Balance issue detected\")\n",
    "                    print(\"     → Use regression adjustment or CUPED\")\n",
    "                    print(\"     → Check for selection bias\")\n",
    "                if not row['temporal_stable']:\n",
    "                    print(\"    Temporal instability detected\")\n",
    "                    print(\"     → Check for system changes during test\")\n",
    "                    print(\"     → Consider excluding unstable periods\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"VALIDATION COMPLETE\")\n",
    "    print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "\n",
    "\n",
    "# MAIN EXECUTION\n",
    "if __name__ == \"__main__\":\n",
    "    validate_all_tests()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93cbc8ad",
   "metadata": {},
   "source": [
    "## Define Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86bbdf40",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pijar2000\\AppData\\Local\\Temp\\ipykernel_16348\\4023069249.py:15: UserWarning: Validation module not available. Skipping validation checks.\n",
      "  warnings.warn(\"Validation module not available. Skipping validation checks.\")\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from scipy.stats import chi2_contingency\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "import warnings\n",
    "\n",
    "# Try to import validation module\n",
    "try:\n",
    "    from validation import ExperimentValidator\n",
    "    VALIDATION_AVAILABLE = True\n",
    "except ImportError:\n",
    "    VALIDATION_AVAILABLE = False\n",
    "    warnings.warn(\"Validation module not available. Skipping validation checks.\")\n",
    "\n",
    "\n",
    "class ABTestAnalyzer:\n",
    "    \n",
    "    def __init__(self, alpha: float = 0.05):\n",
    "        self.alpha = alpha\n",
    "        if VALIDATION_AVAILABLE:\n",
    "            self.validator = ExperimentValidator(srm_threshold=0.001)  # Stricter for SRM\n",
    "        else:\n",
    "            self.validator = None\n",
    "    \n",
    "    def calculate_sample_size(self,\n",
    "                            baseline_rate: float,\n",
    "                            mde: float,\n",
    "                            alpha: float = 0.05,\n",
    "                            power: float = 0.80,\n",
    "                            two_tailed: bool = True) -> int:\n",
    "        \n",
    "        if two_tailed:\n",
    "            z_alpha = stats.norm.ppf(1 - alpha/2)\n",
    "        else:\n",
    "            z_alpha = stats.norm.ppf(1 - alpha)\n",
    "        \n",
    "        z_beta = stats.norm.ppf(power)\n",
    "    \n",
    "        p1 = baseline_rate\n",
    "        p2 = baseline_rate * (1 + mde)\n",
    "        \n",
    "        p2 = min(p2, 0.999)\n",
    "        \n",
    "        numerator = (z_alpha + z_beta) ** 2 * (p1 * (1 - p1) + p2 * (1 - p2))\n",
    "        denominator = (p2 - p1) ** 2\n",
    "        \n",
    "        n = numerator / denominator\n",
    "        \n",
    "        return int(np.ceil(n))\n",
    "    \n",
    "    def two_sample_ttest(self,\n",
    "                        control: np.ndarray,\n",
    "                        treatment: np.ndarray,\n",
    "                        metric_name: str,\n",
    "                        equal_var: bool = False) -> Dict:\n",
    "        \n",
    "        control = control[~np.isnan(control)]\n",
    "        treatment = treatment[~np.isnan(treatment)]\n",
    "        \n",
    "        control_mean = control.mean()\n",
    "        treatment_mean = treatment.mean()\n",
    "        control_std = control.std(ddof=1)\n",
    "        treatment_std = treatment.std(ddof=1)\n",
    "        n_control = len(control)\n",
    "        n_treatment = len(treatment)\n",
    "        \n",
    "        statistic, pvalue = stats.ttest_ind(treatment, control, equal_var=equal_var)\n",
    "        \n",
    "        pooled_std = np.sqrt((control_std**2 + treatment_std**2) / 2)\n",
    "        cohens_d = (treatment_mean - control_mean) / pooled_std if pooled_std > 0 else 0\n",
    "        \n",
    "        se_diff = np.sqrt(control_std**2/n_control + treatment_std**2/n_treatment)\n",
    "        \n",
    "        if not equal_var:\n",
    "            num = (control_std**2/n_control + treatment_std**2/n_treatment)**2\n",
    "            denom = ((control_std**2/n_control)**2/(n_control-1) + \n",
    "                    (treatment_std**2/n_treatment)**2/(n_treatment-1))\n",
    "            df = num / denom if denom > 0 else n_control + n_treatment - 2\n",
    "        else:\n",
    "            df = n_control + n_treatment - 2\n",
    "        \n",
    "        t_crit = stats.t.ppf(1 - self.alpha/2, df)\n",
    "        diff = treatment_mean - control_mean\n",
    "        ci_lower = diff - t_crit * se_diff\n",
    "        ci_upper = diff + t_crit * se_diff\n",
    "        \n",
    "        relative_lift_pct = (diff / control_mean * 100) if control_mean != 0 else 0\n",
    "        \n",
    "        return {\n",
    "            'metric': metric_name,\n",
    "            'test_type': 't-test',\n",
    "            'statistic': statistic,\n",
    "            'pvalue': pvalue,\n",
    "            'significant': pvalue < self.alpha,\n",
    "            'control_mean': control_mean,\n",
    "            'treatment_mean': treatment_mean,\n",
    "            'control_std': control_std,\n",
    "            'treatment_std': treatment_std,\n",
    "            'absolute_diff': diff,\n",
    "            'relative_lift_pct': relative_lift_pct,\n",
    "            'cohens_d': cohens_d,\n",
    "            'ci_lower': ci_lower,\n",
    "            'ci_upper': ci_upper,\n",
    "            'n_control': n_control,\n",
    "            'n_treatment': n_treatment,\n",
    "            'degrees_of_freedom': df\n",
    "        }\n",
    "    \n",
    "    def proportion_test(self,\n",
    "                        control_successes: int,\n",
    "                        control_total: int,\n",
    "                        treatment_successes: int,\n",
    "                        treatment_total: int,\n",
    "                        metric_name: str) -> Dict:\n",
    "        \n",
    "        p_control = control_successes / control_total\n",
    "        p_treatment = treatment_successes / treatment_total\n",
    "        \n",
    "        p_pooled = (control_successes + treatment_successes) / (control_total + treatment_total)\n",
    "        \n",
    "        se = np.sqrt(p_pooled * (1 - p_pooled) * (1/control_total + 1/treatment_total))\n",
    "        \n",
    "        z_stat = (p_treatment - p_control) / se if se > 0 else 0\n",
    "        \n",
    "        pvalue = 2 * (1 - stats.norm.cdf(abs(z_stat)))\n",
    "        \n",
    "        se_diff = np.sqrt(p_control*(1-p_control)/control_total + \n",
    "                        p_treatment*(1-p_treatment)/treatment_total)\n",
    "        z_crit = stats.norm.ppf(1 - self.alpha/2)\n",
    "        diff = p_treatment - p_control\n",
    "        ci_lower = diff - z_crit * se_diff\n",
    "        ci_upper = diff + z_crit * se_diff\n",
    "        \n",
    "        relative_lift_pct = (diff / p_control * 100) if p_control > 0 else 0\n",
    "        \n",
    "        return {\n",
    "            'metric': metric_name,\n",
    "            'test_type': 'proportion_test',\n",
    "            'statistic': z_stat,\n",
    "            'pvalue': pvalue,\n",
    "            'significant': pvalue < self.alpha,\n",
    "            'control_rate': p_control,\n",
    "            'treatment_rate': p_treatment,\n",
    "            'absolute_diff': diff,\n",
    "            'relative_lift_pct': relative_lift_pct,\n",
    "            'ci_lower': ci_lower,\n",
    "            'ci_upper': ci_upper,\n",
    "            'n_control': control_total,\n",
    "            'n_treatment': treatment_total\n",
    "        }\n",
    "\n",
    "    def chi_square_test(self,\n",
    "                        control: np.ndarray,\n",
    "                        treatment: np.ndarray,\n",
    "                        metric_name: str) -> Dict:\n",
    "        \n",
    "        combined = np.concatenate([control, treatment])\n",
    "        labels = np.concatenate([np.zeros(len(control)), np.ones(len(treatment))])\n",
    "        \n",
    "        contingency_table = pd.crosstab(combined, labels)\n",
    "        \n",
    "        chi2, pvalue, dof, expected = chi2_contingency(contingency_table)\n",
    "\n",
    "        n = len(combined)\n",
    "        min_dim = min(contingency_table.shape[0], contingency_table.shape[1]) - 1\n",
    "        cramers_v = np.sqrt(chi2 / (n * min_dim)) if min_dim > 0 else 0\n",
    "        \n",
    "        return {\n",
    "            'metric': metric_name,\n",
    "            'test_type': 'chi_square',\n",
    "            'statistic': chi2,\n",
    "            'pvalue': pvalue,\n",
    "            'significant': pvalue < self.alpha,\n",
    "            'degrees_of_freedom': dof,\n",
    "            'cramers_v': cramers_v,\n",
    "            'n_control': len(control),\n",
    "            'n_treatment': len(treatment)\n",
    "        }\n",
    "    \n",
    "    def mann_whitney_u_test(self,\n",
    "                            control: np.ndarray,\n",
    "                            treatment: np.ndarray,\n",
    "                            metric_name: str) -> Dict:\n",
    "\n",
    "        control = control[~np.isnan(control)]\n",
    "        treatment = treatment[~np.isnan(treatment)]\n",
    "        \n",
    "        statistic, pvalue = stats.mannwhitneyu(treatment, control, alternative='two-sided')\n",
    "        \n",
    "        n1 = len(control)\n",
    "        n2 = len(treatment)\n",
    "        rank_biserial = 1 - (2*statistic) / (n1 * n2)\n",
    "        \n",
    "        control_median = np.median(control)\n",
    "        treatment_median = np.median(treatment)\n",
    "        \n",
    "        return {\n",
    "            'metric': metric_name,\n",
    "            'test_type': 'mann_whitney',\n",
    "            'statistic': statistic,\n",
    "            'pvalue': pvalue,\n",
    "            'significant': pvalue < self.alpha,\n",
    "            'control_median': control_median,\n",
    "            'treatment_median': treatment_median,\n",
    "            'rank_biserial': rank_biserial,\n",
    "            'n_control': n1,\n",
    "            'n_treatment': n2\n",
    "        }\n",
    "    \n",
    "    def bootstrap_confidence_interval(self,\n",
    "                                    control: np.ndarray,\n",
    "                                    treatment: np.ndarray,\n",
    "                                    metric_name: str,\n",
    "                                    n_bootstrap: int = 10000,\n",
    "                                    confidence_level: float = 0.95) -> Dict:\n",
    "        \n",
    "        np.random.seed(42)\n",
    "        \n",
    "        control = control[~np.isnan(control)]\n",
    "        treatment = treatment[~np.isnan(treatment)]\n",
    "        \n",
    "        boot_diffs = []\n",
    "        for _ in range(n_bootstrap):\n",
    "            control_boot = np.random.choice(control, size=len(control), replace=True)\n",
    "            treatment_boot = np.random.choice(treatment, size=len(treatment), replace=True)\n",
    "            boot_diffs.append(treatment_boot.mean() - control_boot.mean())\n",
    "        \n",
    "        boot_diffs = np.array(boot_diffs)\n",
    "        \n",
    "        alpha_bootstrap = 1 - confidence_level\n",
    "        ci_lower = np.percentile(boot_diffs, alpha_bootstrap/2 * 100)\n",
    "        ci_upper = np.percentile(boot_diffs, (1 - alpha_bootstrap/2) * 100)\n",
    "        \n",
    "        observed_diff = treatment.mean() - control.mean()\n",
    "\n",
    "        significant = not (ci_lower <= 0 <= ci_upper)\n",
    "        \n",
    "        return {\n",
    "            'metric': metric_name,\n",
    "            'test_type': 'bootstrap',\n",
    "            'observed_diff': observed_diff,\n",
    "            'ci_lower': ci_lower,\n",
    "            'ci_upper': ci_upper,\n",
    "            'significant': significant,\n",
    "            'confidence_level': confidence_level,\n",
    "            'n_bootstrap': n_bootstrap\n",
    "        }\n",
    "    \n",
    "    def multiple_testing_correction(self,\n",
    "                                    p_values: List[float],\n",
    "                                    method: str = 'holm') -> Dict:\n",
    "\n",
    "        reject, pvals_corrected, alphacSidak, alphacBonf = multipletests(\n",
    "            p_values, \n",
    "            alpha=self.alpha, \n",
    "            method=method\n",
    "        )\n",
    "        \n",
    "        fwer_uncorrected = 1 - (1 - self.alpha) ** len(p_values)\n",
    "        \n",
    "        return {\n",
    "            'method': method,\n",
    "            'original_pvalues': p_values,\n",
    "            'corrected_pvalues': pvals_corrected.tolist(),\n",
    "            'reject': reject.tolist(),\n",
    "            'fwer_uncorrected': fwer_uncorrected,\n",
    "            'num_tests': len(p_values),\n",
    "            'num_significant_uncorrected': sum(p < self.alpha for p in p_values),\n",
    "            'num_significant_corrected': sum(reject)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68f10d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy import stats\n",
    "\n",
    "def drive_ab_analysis(df, analyzer):\n",
    "    print(\"DRIVER STARTING...\\n\")\n",
    "    \n",
    "    # 1. Setup Data\n",
    "    try:\n",
    "        col_list = df.columns.tolist()\n",
    "        var_idx = col_list.index('variant')\n",
    "        metric_cols = col_list[var_idx+1:] \n",
    "        \n",
    "        variants = sorted(df['variant'].unique())\n",
    "        n_variants = len(variants)\n",
    "        \n",
    "        print(f\"Control/Variants: {variants}\")\n",
    "        print(f\"Metrics to analyze: {metric_cols}\\n\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error Setup: {e}\")\n",
    "        return\n",
    "\n",
    "    # List Penampung Sementara\n",
    "    temp_results = []\n",
    "    raw_pvalues = []\n",
    "\n",
    "    # 2. FASE 1: HITUNG STATISTIK MENTAH (Belum print tabel)\n",
    "    for metric in metric_cols:\n",
    "        \n",
    "        # --- JALUR A: KASUS > 2 VARIAN ---\n",
    "        if n_variants > 2:\n",
    "            unique_vals = df[metric].dropna().unique()\n",
    "            is_binary = set(unique_vals).issubset({0, 1, 0.0, 1.0})\n",
    "            \n",
    "            if is_binary:\n",
    "                test_name = 'Chi-Square (K>2)'\n",
    "                contingency = pd.crosstab(df['variant'], df[metric])\n",
    "                chi2, p_val, dof, _ = stats.chi2_contingency(contingency)\n",
    "                \n",
    "                result = {\n",
    "                    'metric': metric,\n",
    "                    'test_type': 'chi_square_k_variants',\n",
    "                    'statistic': chi2,\n",
    "                    'pvalue': p_val,\n",
    "                    'dof': dof\n",
    "                }\n",
    "            else:\n",
    "                test_name = 'Kruskal-Wallis'\n",
    "                groups = [df[df['variant'] == v][metric].dropna() for v in variants]\n",
    "                stat, p_val = stats.kruskal(*groups)\n",
    "                \n",
    "                result = {\n",
    "                    'metric': metric,\n",
    "                    'test_type': 'kruskal_wallis',\n",
    "                    'statistic': stat,\n",
    "                    'pvalue': p_val\n",
    "                }\n",
    "            \n",
    "            # Simpan hasil sementara\n",
    "            temp_results.append({\n",
    "                'metric': metric,\n",
    "                'test_name': test_name,\n",
    "                'p_raw': p_val,\n",
    "                'main_result': result,\n",
    "                'boot_result': None\n",
    "            })\n",
    "            raw_pvalues.append(p_val)\n",
    "\n",
    "        # --- JALUR B: KASUS 2 VARIAN (A/B) ---\n",
    "        else:\n",
    "            control_name, treat_name = variants[0], variants[1]\n",
    "            data_c = df[df['variant'] == control_name][metric]\n",
    "            data_t = df[df['variant'] == treat_name][metric]\n",
    "            \n",
    "            unique_vals = df[metric].dropna().unique()\n",
    "            is_binary = set(unique_vals).issubset({0, 1, 0.0, 1.0})\n",
    "\n",
    "            if is_binary:\n",
    "                test_name = 'Proportion Test'\n",
    "                result = analyzer.proportion_test(\n",
    "                    control_successes=data_c.sum(), \n",
    "                    control_total=len(data_c), \n",
    "                    treatment_successes=data_t.sum(), \n",
    "                    treatment_total=len(data_t), \n",
    "                    metric_name=metric\n",
    "                )\n",
    "            else:\n",
    "                test_name = 'Mann-Whitney U'\n",
    "                result = analyzer.mann_whitney_u_test(\n",
    "                    control=data_c, \n",
    "                    treatment=data_t, \n",
    "                    metric_name=metric\n",
    "                )\n",
    "\n",
    "            # Bootstrap\n",
    "            boot_res = analyzer.bootstrap_confidence_interval(data_c, data_t, metric)\n",
    "\n",
    "            # Simpan hasil sementara\n",
    "            temp_results.append({\n",
    "                'metric': metric,\n",
    "                'test_name': test_name,\n",
    "                'p_raw': result['pvalue'],\n",
    "                'main_result': result,\n",
    "                'boot_result': boot_res\n",
    "            })\n",
    "            raw_pvalues.append(result['pvalue'])\n",
    "\n",
    "    # 3. FASE 2: KOREKSI P-VALUE (Multiple Testing Correction)\n",
    "    # Ini langkah penting yang kamu minta\n",
    "    correction_res = analyzer.multiple_testing_correction(raw_pvalues, method='holm')\n",
    "    corrected_pvals = correction_res['corrected_pvalues']\n",
    "    reject_decisions = correction_res['reject'] # True = Signifikan, False = Tidak\n",
    "\n",
    "    # 4. FASE 3: PRINT TABEL SUMMARY\n",
    "    print(\"=\"*100)\n",
    "    print(f\"{'METRIC':<25} | {'TEST TYPE':<18} | {'RAW P-VAL':<10} | {'CORR P-VAL':<10} | {'SIG (CORR)?'}\")\n",
    "    print(\"-\" * 100)\n",
    "    \n",
    "    for i, item in enumerate(temp_results):\n",
    "        metric = item['metric']\n",
    "        test_type = item['test_name']\n",
    "        p_raw = item['p_raw']\n",
    "        \n",
    "        # Ambil data hasil koreksi\n",
    "        p_corr = corrected_pvals[i]\n",
    "        is_sig = \"YES\" if reject_decisions[i] else \"NO\"\n",
    "        \n",
    "        print(f\"{metric:<25} | {test_type:<18} | {p_raw:.5f}    | {p_corr:.5f}     | {is_sig}\")\n",
    "    \n",
    "    print(\"=\"*100 + \"\\n\")\n",
    "\n",
    "    # 5. FASE 4: PRINT DETAIL RETURN (Raw Dictionary)\n",
    "    print(\"DETAILED RETURN VALUES (RAW DICTIONARY)\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    for item in temp_results:\n",
    "        print(f\"METRIC: {item['metric']}\")\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "        print(\"Function Return (Main Test):\")\n",
    "        for key, value in item['main_result'].items():\n",
    "            print(f\"   {key:<20} : {value}\")\n",
    "            \n",
    "        if item['boot_result'] is not None:\n",
    "            print(\"\\nFunction Return (Bootstrap):\")\n",
    "            for key, value in item['boot_result'].items():\n",
    "                print(f\"   {key:<20} : {value}\")\n",
    "        else:\n",
    "             print(\"\\nFunction Return (Bootstrap):\")\n",
    "             print(\"   Skipped (Not applicable for >2 variants)\")\n",
    "            \n",
    "        print(\"\\n\" + \"-\"*80 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7646608",
   "metadata": {},
   "source": [
    "## Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b991c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BATCH ANALYSIS STARTED...\n",
      "\n",
      "####################################################################################################\n",
      "PROCESSING FILE: raw_dataset/test1_menu.csv\n",
      "####################################################################################################\n",
      "DRIVER STARTING...\n",
      "\n",
      "Control/Variants: ['A_horizontal_menu', 'B_dropdown_menu']\n",
      "Metrics to analyze: ['pages_viewed', 'added_to_cart', 'bounced', 'revenue']\n",
      "\n",
      "====================================================================================================\n",
      "METRIC                    | TEST TYPE          | RAW P-VAL  | CORR P-VAL | SIG (CORR)?\n",
      "----------------------------------------------------------------------------------------------------\n",
      "pages_viewed              | Mann-Whitney U     | 0.06748    | 0.13497     | NO\n",
      "added_to_cart             | Proportion Test    | 0.00000    | 0.00000     | YES\n",
      "bounced                   | Proportion Test    | 0.33544    | 0.33544     | NO\n",
      "revenue                   | Mann-Whitney U     | 0.00000    | 0.00000     | YES\n",
      "====================================================================================================\n",
      "\n",
      "DETAILED RETURN VALUES (RAW DICTIONARY)\n",
      "================================================================================\n",
      "METRIC: pages_viewed\n",
      "----------------------------------------\n",
      "Function Return (Main Test):\n",
      "   metric               : pages_viewed\n",
      "   test_type            : mann_whitney\n",
      "   statistic            : 5970453.0\n",
      "   pvalue               : 0.06748254318088377\n",
      "   significant          : False\n",
      "   control_median       : 2.1718126582304853\n",
      "   treatment_median     : 2.129281589369583\n",
      "   rank_biserial        : 0.025232163265306085\n",
      "   n_control            : 3500\n",
      "   n_treatment          : 3500\n",
      "\n",
      "Function Return (Bootstrap):\n",
      "   metric               : pages_viewed\n",
      "   test_type            : bootstrap\n",
      "   observed_diff        : -0.044001366759339966\n",
      "   ci_lower             : -0.0781899587715267\n",
      "   ci_upper             : -0.009201208245586935\n",
      "   significant          : True\n",
      "   confidence_level     : 0.95\n",
      "   n_bootstrap          : 10000\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "METRIC: added_to_cart\n",
      "----------------------------------------\n",
      "Function Return (Main Test):\n",
      "   metric               : added_to_cart\n",
      "   test_type            : proportion_test\n",
      "   statistic            : -14.682211257485458\n",
      "   pvalue               : 0.0\n",
      "   significant          : True\n",
      "   control_rate         : 0.9617142857142857\n",
      "   treatment_rate       : 0.8622857142857143\n",
      "   absolute_diff        : -0.09942857142857142\n",
      "   relative_lift_pct    : -10.33868092691622\n",
      "   ci_lower             : -0.11249556177917239\n",
      "   ci_upper             : -0.08636158107797046\n",
      "   n_control            : 3500\n",
      "   n_treatment          : 3500\n",
      "\n",
      "Function Return (Bootstrap):\n",
      "   metric               : added_to_cart\n",
      "   test_type            : bootstrap\n",
      "   observed_diff        : -0.09942857142857142\n",
      "   ci_lower             : -0.11257142857142854\n",
      "   ci_upper             : -0.0862857142857143\n",
      "   significant          : True\n",
      "   confidence_level     : 0.95\n",
      "   n_bootstrap          : 10000\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "METRIC: bounced\n",
      "----------------------------------------\n",
      "Function Return (Main Test):\n",
      "   metric               : bounced\n",
      "   test_type            : proportion_test\n",
      "   statistic            : 0.963209836231947\n",
      "   pvalue               : 0.33544222989520955\n",
      "   significant          : False\n",
      "   control_rate         : 0.434\n",
      "   treatment_rate       : 0.44542857142857145\n",
      "   absolute_diff        : 0.011428571428571455\n",
      "   relative_lift_pct    : 2.6333113890717637\n",
      "   ci_lower             : -0.011825036552998412\n",
      "   ci_upper             : 0.03468217941014132\n",
      "   n_control            : 3500\n",
      "   n_treatment          : 3500\n",
      "\n",
      "Function Return (Bootstrap):\n",
      "   metric               : bounced\n",
      "   test_type            : bootstrap\n",
      "   observed_diff        : 0.011428571428571455\n",
      "   ci_lower             : -0.011428571428571399\n",
      "   ci_upper             : 0.03429285714285706\n",
      "   significant          : False\n",
      "   confidence_level     : 0.95\n",
      "   n_bootstrap          : 10000\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "METRIC: revenue\n",
      "----------------------------------------\n",
      "Function Return (Main Test):\n",
      "   metric               : revenue\n",
      "   test_type            : mann_whitney\n",
      "   statistic            : 5653101.0\n",
      "   pvalue               : 2.3774545029315777e-08\n",
      "   significant          : True\n",
      "   control_median       : 2.8623538075014805\n",
      "   treatment_median     : 2.6020784612970225\n",
      "   rank_biserial        : 0.07704473469387751\n",
      "   n_control            : 3500\n",
      "   n_treatment          : 3500\n",
      "\n",
      "Function Return (Bootstrap):\n",
      "   metric               : revenue\n",
      "   test_type            : bootstrap\n",
      "   observed_diff        : -0.36742081971290474\n",
      "   ci_lower             : -0.4783761664666615\n",
      "   ci_upper             : -0.2546086310625131\n",
      "   significant          : True\n",
      "   confidence_level     : 0.95\n",
      "   n_bootstrap          : 10000\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "                                        --- END OF FILE ---\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "PROCESSING FILE: raw_dataset/test2_novelty_slider.csv\n",
      "####################################################################################################\n",
      "DRIVER STARTING...\n",
      "\n",
      "Control/Variants: ['A_manual_novelties', 'B_personalized_novelties']\n",
      "Metrics to analyze: ['is_registered', 'novelty_revenue', 'products_added_from_novelties']\n",
      "\n",
      "====================================================================================================\n",
      "METRIC                    | TEST TYPE          | RAW P-VAL  | CORR P-VAL | SIG (CORR)?\n",
      "----------------------------------------------------------------------------------------------------\n",
      "is_registered             | Proportion Test    | 0.89884    | 0.89884     | NO\n",
      "novelty_revenue           | Mann-Whitney U     | 0.00000    | 0.00000     | YES\n",
      "products_added_from_novelties | Proportion Test    | 0.00001    | 0.00002     | YES\n",
      "====================================================================================================\n",
      "\n",
      "DETAILED RETURN VALUES (RAW DICTIONARY)\n",
      "================================================================================\n",
      "METRIC: is_registered\n",
      "----------------------------------------\n",
      "Function Return (Main Test):\n",
      "   metric               : is_registered\n",
      "   test_type            : proportion_test\n",
      "   statistic            : -0.12712513905518094\n",
      "   pvalue               : 0.8988413547910823\n",
      "   significant          : False\n",
      "   control_rate         : 0.450625\n",
      "   treatment_rate       : 0.449625\n",
      "   absolute_diff        : -0.0010000000000000009\n",
      "   relative_lift_pct    : -0.22191400832177552\n",
      "   ci_lower             : -0.01641758781367529\n",
      "   ci_upper             : 0.01441758781367529\n",
      "   n_control            : 8000\n",
      "   n_treatment          : 8000\n",
      "\n",
      "Function Return (Bootstrap):\n",
      "   metric               : is_registered\n",
      "   test_type            : bootstrap\n",
      "   observed_diff        : -0.0010000000000000009\n",
      "   ci_lower             : -0.016749999999999987\n",
      "   ci_upper             : 0.014249999999999985\n",
      "   significant          : False\n",
      "   confidence_level     : 0.95\n",
      "   n_bootstrap          : 10000\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "METRIC: novelty_revenue\n",
      "----------------------------------------\n",
      "Function Return (Main Test):\n",
      "   metric               : novelty_revenue\n",
      "   test_type            : mann_whitney\n",
      "   statistic            : 33612111.0\n",
      "   pvalue               : 3.41884878278823e-08\n",
      "   significant          : True\n",
      "   control_median       : 3.77300331934513\n",
      "   treatment_median     : 3.9818526425194394\n",
      "   rank_biserial        : -0.05037846874999996\n",
      "   n_control            : 8000\n",
      "   n_treatment          : 8000\n",
      "\n",
      "Function Return (Bootstrap):\n",
      "   metric               : novelty_revenue\n",
      "   test_type            : bootstrap\n",
      "   observed_diff        : 0.24563814419945285\n",
      "   ci_lower             : 0.16845382596152456\n",
      "   ci_upper             : 0.3222507761514787\n",
      "   significant          : True\n",
      "   confidence_level     : 0.95\n",
      "   n_bootstrap          : 10000\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "METRIC: products_added_from_novelties\n",
      "----------------------------------------\n",
      "Function Return (Main Test):\n",
      "   metric               : products_added_from_novelties\n",
      "   test_type            : proportion_test\n",
      "   statistic            : 4.472532542293338\n",
      "   pvalue               : 7.729863223948641e-06\n",
      "   significant          : True\n",
      "   control_rate         : 0.0015\n",
      "   treatment_rate       : 0.00575\n",
      "   absolute_diff        : 0.00425\n",
      "   relative_lift_pct    : 283.33333333333337\n",
      "   ci_lower             : 0.0023887193610504813\n",
      "   ci_upper             : 0.006111280638949519\n",
      "   n_control            : 8000\n",
      "   n_treatment          : 8000\n",
      "\n",
      "Function Return (Bootstrap):\n",
      "   metric               : products_added_from_novelties\n",
      "   test_type            : bootstrap\n",
      "   observed_diff        : 0.00425\n",
      "   ci_lower             : 0.0023750000000000004\n",
      "   ci_upper             : 0.006125\n",
      "   significant          : True\n",
      "   confidence_level     : 0.95\n",
      "   n_bootstrap          : 10000\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "                                        --- END OF FILE ---\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "PROCESSING FILE: raw_dataset/test3_product_sliders.csv\n",
      "####################################################################################################\n",
      "DRIVER STARTING...\n",
      "\n",
      "Control/Variants: ['A_selected_by_others_only', 'B_similar_products_top', 'C_selected_by_others_top']\n",
      "Metrics to analyze: ['add_to_cart_rate', 'slider_interactions', 'revenue_from_recommendations', 'products_per_order', 'avg_product_price']\n",
      "\n",
      "====================================================================================================\n",
      "METRIC                    | TEST TYPE          | RAW P-VAL  | CORR P-VAL | SIG (CORR)?\n",
      "----------------------------------------------------------------------------------------------------\n",
      "add_to_cart_rate          | Chi-Square (K>2)   | 0.98885    | 0.98885     | NO\n",
      "slider_interactions       | Kruskal-Wallis     | 0.16215    | 0.32430     | NO\n",
      "revenue_from_recommendations | Kruskal-Wallis     | 0.00000    | 0.00000     | YES\n",
      "products_per_order        | Kruskal-Wallis     | 0.00000    | 0.00000     | YES\n",
      "avg_product_price         | Kruskal-Wallis     | 0.00000    | 0.00000     | YES\n",
      "====================================================================================================\n",
      "\n",
      "DETAILED RETURN VALUES (RAW DICTIONARY)\n",
      "================================================================================\n",
      "METRIC: add_to_cart_rate\n",
      "----------------------------------------\n",
      "Function Return (Main Test):\n",
      "   metric               : add_to_cart_rate\n",
      "   test_type            : chi_square_k_variants\n",
      "   statistic            : 0.022431639578384874\n",
      "   pvalue               : 0.9888468430271623\n",
      "   dof                  : 2\n",
      "\n",
      "Function Return (Bootstrap):\n",
      "   Skipped (Not applicable for >2 variants)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "METRIC: slider_interactions\n",
      "----------------------------------------\n",
      "Function Return (Main Test):\n",
      "   metric               : slider_interactions\n",
      "   test_type            : kruskal_wallis\n",
      "   statistic            : 3.638452245086987\n",
      "   pvalue               : 0.16215118753992264\n",
      "\n",
      "Function Return (Bootstrap):\n",
      "   Skipped (Not applicable for >2 variants)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "METRIC: revenue_from_recommendations\n",
      "----------------------------------------\n",
      "Function Return (Main Test):\n",
      "   metric               : revenue_from_recommendations\n",
      "   test_type            : kruskal_wallis\n",
      "   statistic            : 240.81111669412348\n",
      "   pvalue               : 5.111288789045014e-53\n",
      "\n",
      "Function Return (Bootstrap):\n",
      "   Skipped (Not applicable for >2 variants)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "METRIC: products_per_order\n",
      "----------------------------------------\n",
      "Function Return (Main Test):\n",
      "   metric               : products_per_order\n",
      "   test_type            : kruskal_wallis\n",
      "   statistic            : 42.69457486386302\n",
      "   pvalue               : 5.357853872650724e-10\n",
      "\n",
      "Function Return (Bootstrap):\n",
      "   Skipped (Not applicable for >2 variants)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "METRIC: avg_product_price\n",
      "----------------------------------------\n",
      "Function Return (Main Test):\n",
      "   metric               : avg_product_price\n",
      "   test_type            : kruskal_wallis\n",
      "   statistic            : 298.6190511888187\n",
      "   pvalue               : 1.4311888323774657e-65\n",
      "\n",
      "Function Return (Bootstrap):\n",
      "   Skipped (Not applicable for >2 variants)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "                                        --- END OF FILE ---\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "PROCESSING FILE: raw_dataset/test4_reviews.csv\n",
      "####################################################################################################\n",
      "DRIVER STARTING...\n",
      "\n",
      "Control/Variants: ['A_no_featured_reviews', 'B_featured_reviews']\n",
      "Metrics to analyze: ['converted', 'added_to_cart']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "analyzer = ABTestAnalyzer()\n",
    "\n",
    "files_to_test = [\n",
    "    'raw_dataset/test1_menu.csv',\n",
    "    'raw_dataset/test2_novelty_slider.csv',\n",
    "    'raw_dataset/test3_product_sliders.csv',\n",
    "    'raw_dataset/test4_reviews.csv',\n",
    "    'raw_dataset/test5_search_engine.csv'\n",
    "]\n",
    "\n",
    "print(\"BATCH ANALYSIS STARTED...\\n\")\n",
    "\n",
    "# 3. Loop\n",
    "for filepath in files_to_test:\n",
    "    print(\"#\" * 100)\n",
    "    print(f\"PROCESSING FILE: {filepath}\")\n",
    "    print(\"#\" * 100)\n",
    "    \n",
    "    if os.path.exists(filepath):\n",
    "        # Load Data\n",
    "        df_loop = pd.read_csv(filepath)\n",
    "\n",
    "        drive_ab_analysis(df_loop, analyzer)\n",
    "        \n",
    "    else:\n",
    "        print(f\"File not found: {filepath}. Skipping...\")\n",
    "    \n",
    "    print(\"\\n\" + \" \"*40 + \"--- END OF FILE ---\\n\\n\")\n",
    "\n",
    "print(\"ALL ANALYSES COMPLETED.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
